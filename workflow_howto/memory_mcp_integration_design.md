# Memory MCPä¸InteractionLogManageræ•´åˆæ–¹æ¡ˆ

## ğŸ¯ æ•´åˆç›®æ ‡

<<<<<<< HEAD
å°†PowerAutomationçš„Unified Memory MCPä¸æˆ‘ä»¬çš„InteractionLogManageræ•´åˆï¼Œå®ç°ï¼š
=======
åŸºäºPowerAutomationç°æœ‰çš„SuperMemoryé€‚é…å™¨å’ŒUnified Memory MCPï¼Œå°†è®°å¿†ç³»ç»Ÿä¸æˆ‘ä»¬çš„InteractionLogManageræ•´åˆï¼Œå®ç°ï¼š
>>>>>>> 2964a240aef572f0ac8f6da7f8da0533a8eed647

### **1. æ™ºèƒ½è®°å¿†ç®¡ç†**
- è‡ªåŠ¨å°†äº¤äº’æ•°æ®è½¬æ¢ä¸ºé•¿æœŸè®°å¿†
- åŸºäºç”¨æˆ·è¡Œä¸ºæ¨¡å¼ä¼˜åŒ–è®°å¿†å­˜å‚¨
- è·¨ä¼šè¯çš„ä¸Šä¸‹æ–‡ä¿æŒå’Œå­¦ä¹ 

### **2. å¢å¼ºçš„å†³ç­–èƒ½åŠ›**
- åŸºäºå†å²è®°å¿†ä¼˜åŒ–è·¯ç”±å†³ç­–
- ä¸ªæ€§åŒ–çš„workflowæ¨è
- é¢„æµ‹æ€§çš„ç”¨æˆ·éœ€æ±‚åˆ†æ

### **3. ç»Ÿä¸€çš„æ•°æ®ç”Ÿæ€**
- äº¤äº’æ•°æ® â†’ è®°å¿†å­˜å‚¨ â†’ æ™ºèƒ½æ£€ç´¢
- å¤šæºè®°å¿†çš„ç»Ÿä¸€ç®¡ç†
- å®æ—¶å­¦ä¹ å’Œä¼˜åŒ–

<<<<<<< HEAD
## ğŸ—ï¸ æ•´åˆæ¶æ„è®¾è®¡

### **æ ¸å¿ƒç»„ä»¶å…³ç³»**
=======
## ğŸ—ï¸ åŸºäºç°æœ‰æ¶æ„çš„æ•´åˆè®¾è®¡

### **ç°æœ‰ç»„ä»¶åˆ†æ**

#### **1. SuperMemoryé€‚é…å™¨ç‰¹æ€§**
- âœ… å®ç°äº†`KiloCodeAdapterInterface`æ ‡å‡†æ¥å£
- âœ… æä¾›å®Œæ•´çš„è®°å¿†CRUDæ“ä½œ
- âœ… æ”¯æŒAPIå¯†é’¥è®¤è¯å’Œé…ç½®ç®¡ç†
- âœ… å®Œå–„çš„é”™è¯¯å¤„ç†å’Œå¥åº·æ£€æŸ¥

#### **2. Unified Memory MCPç‰¹æ€§**
- âœ… å¤šæºè®°å¿†ç®¡ç†ï¼ˆGitHubã€SuperMemoryã€RAGã€æœ¬åœ°ï¼‰
- âœ… ä¸°å¯Œçš„æ“ä½œæ¥å£ï¼ˆqueryã€insertã€updateã€deleteç­‰ï¼‰
- âœ… å®Œæ•´çš„ç»Ÿè®¡å’Œç›‘æ§ç³»ç»Ÿ
- âœ… å‘é‡æ£€ç´¢å’Œè¯­ä¹‰æœç´¢

### **æ•´åˆæ¶æ„è®¾è®¡**
>>>>>>> 2964a240aef572f0ac8f6da7f8da0533a8eed647

```
MCPCoordinator {
    InteractionLogManager {
        - æ”¶é›†äº¤äº’æ•°æ®
        - å®æ—¶æ•°æ®åˆ†æ
        - è§¦å‘è®°å¿†å­˜å‚¨
    }
    
<<<<<<< HEAD
    MemoryMCP {
        - é•¿æœŸè®°å¿†ç®¡ç†
        - æ™ºèƒ½æ£€ç´¢æœåŠ¡
        - è·¨æºè®°å¿†æ•´åˆ
    }
    
    SmartRouter {
=======
    UnifiedMemoryMCP {
        - SuperMemoryAdapter (å¤–éƒ¨è®°å¿†æœåŠ¡)
        - LocalMemoryAdapter (æœ¬åœ°è®°å¿†å­˜å‚¨)
        - RAGMemoryAdapter (å‘é‡æ£€ç´¢)
        - GitHubMemoryAdapter (ä»£ç è®°å¿†)
    }
    
    MemoryEnhancedRouter {
>>>>>>> 2964a240aef572f0ac8f6da7f8da0533a8eed647
        - åŸºäºè®°å¿†çš„è·¯ç”±å†³ç­–
        - ä¸ªæ€§åŒ–æ¨è
        - é¢„æµ‹æ€§åˆ†æ
    }
}
```

<<<<<<< HEAD
### **æ•°æ®æµè®¾è®¡**

```
ç”¨æˆ·è¯·æ±‚ â†’ MCPå¤„ç† â†’ äº¤äº’æ•°æ® â†’ InteractionLogManager
                                        â†“
è®°å¿†æ£€ç´¢ â† MemoryMCP â† è®°å¿†è½¬æ¢ â† æ•°æ®åˆ†æ
    â†“
SmartRouter â†’ ä¼˜åŒ–å†³ç­– â†’ ä¸ªæ€§åŒ–å“åº”
```

=======
>>>>>>> 2964a240aef572f0ac8f6da7f8da0533a8eed647
## ğŸ”§ æŠ€æœ¯å®ç°æ–¹æ¡ˆ

### **1. è®°å¿†æ•°æ®è½¬æ¢å™¨ (MemoryDataConverter)**

```python
<<<<<<< HEAD
class MemoryDataConverter:
    """å°†äº¤äº’æ•°æ®è½¬æ¢ä¸ºè®°å¿†æ ¼å¼"""
    
    def convert_interaction_to_memory(self, interaction_data: Dict) -> Dict:
        """è½¬æ¢äº¤äº’æ•°æ®ä¸ºè®°å¿†æ ¼å¼"""
        return {
            "content": self._extract_content(interaction_data),
            "metadata": {
                "user_id": interaction_data.get("user_id"),
                "mcp_type": interaction_data.get("mcp_type"),
                "operation": interaction_data.get("operation"),
                "timestamp": interaction_data.get("timestamp"),
                "success": interaction_data.get("success"),
                "response_time": interaction_data.get("response_time"),
                "context": interaction_data.get("context", {}),
                "tags": self._generate_tags(interaction_data)
            },
            "source": "interaction_log"
        }
    
    def _extract_content(self, interaction_data: Dict) -> str:
        """æå–å…³é”®å†…å®¹"""
        content_parts = []
        
        # ç”¨æˆ·è¯·æ±‚å†…å®¹
        if "request" in interaction_data:
            content_parts.append(f"ç”¨æˆ·è¯·æ±‚: {interaction_data['request']}")
        
        # å¤„ç†ç»“æœ
        if "response" in interaction_data:
            content_parts.append(f"å¤„ç†ç»“æœ: {interaction_data['response']}")
=======
import hashlib
import json
from typing import Dict, List, Any, Optional
from datetime import datetime

class MemoryDataConverter:
    """å°†äº¤äº’æ•°æ®è½¬æ¢ä¸ºè®°å¿†æ ¼å¼ï¼Œå…¼å®¹SuperMemoryé€‚é…å™¨"""
    
    def __init__(self, supermemory_adapter: SuperMemoryAdapter):
        self.supermemory = supermemory_adapter
        self.memory_rules = self._load_memory_rules()
    
    def convert_interaction_to_memory(self, interaction_data: Dict) -> Dict:
        """è½¬æ¢äº¤äº’æ•°æ®ä¸ºè®°å¿†æ ¼å¼"""
        # ç”Ÿæˆå”¯ä¸€çš„è®°å¿†é”®
        memory_key = self._generate_memory_key(interaction_data)
        
        # æå–å’Œç»“æ„åŒ–å†…å®¹
        content = self._extract_structured_content(interaction_data)
        
        # ç”Ÿæˆå…ƒæ•°æ®
        metadata = self._generate_metadata(interaction_data)
        
        return {
            "key": memory_key,
            "content": content,
            "metadata": metadata,
            "source": "interaction_log",
            "timestamp": datetime.now().isoformat()
        }
    
    def _generate_memory_key(self, interaction_data: Dict) -> str:
        """ç”Ÿæˆå”¯ä¸€çš„è®°å¿†é”®"""
        # åŸºäºç”¨æˆ·IDã€æ—¶é—´æˆ³å’Œå†…å®¹å“ˆå¸Œç”Ÿæˆå”¯ä¸€é”®
        user_id = interaction_data.get("user_id", "anonymous")
        timestamp = interaction_data.get("timestamp", "")
        content_hash = hashlib.md5(
            str(interaction_data.get("request", "")).encode()
        ).hexdigest()[:8]
        
        return f"interaction_{user_id}_{timestamp}_{content_hash}"
    
    def _extract_structured_content(self, interaction_data: Dict) -> str:
        """æå–ç»“æ„åŒ–å†…å®¹"""
        content_parts = []
        
        # ç”¨æˆ·è¯·æ±‚
        if "request" in interaction_data:
            content_parts.append(f"ç”¨æˆ·è¯·æ±‚: {interaction_data['request']}")
        
        # MCPç±»å‹å’Œæ“ä½œ
        mcp_type = interaction_data.get("mcp_type", "")
        operation = interaction_data.get("operation", "")
        if mcp_type and operation:
            content_parts.append(f"å¤„ç†æ–¹å¼: {mcp_type}.{operation}")
        
        # å¤„ç†ç»“æœ
        if "response" in interaction_data:
            response = interaction_data['response']
            if isinstance(response, dict):
                response = json.dumps(response, ensure_ascii=False)
            content_parts.append(f"å¤„ç†ç»“æœ: {response}")
        
        # æ€§èƒ½ä¿¡æ¯
        response_time = interaction_data.get("response_time", 0)
        if response_time:
            content_parts.append(f"å“åº”æ—¶é—´: {response_time}ms")
>>>>>>> 2964a240aef572f0ac8f6da7f8da0533a8eed647
        
        # é”™è¯¯ä¿¡æ¯
        if "error" in interaction_data:
            content_parts.append(f"é”™è¯¯ä¿¡æ¯: {interaction_data['error']}")
        
        return " | ".join(content_parts)
    
<<<<<<< HEAD
=======
    def _generate_metadata(self, interaction_data: Dict) -> Dict:
        """ç”Ÿæˆè®°å¿†å…ƒæ•°æ®"""
        metadata = {
            "user_id": interaction_data.get("user_id", "anonymous"),
            "mcp_type": interaction_data.get("mcp_type", ""),
            "operation": interaction_data.get("operation", ""),
            "timestamp": interaction_data.get("timestamp", ""),
            "success": interaction_data.get("success", False),
            "response_time": interaction_data.get("response_time", 0),
            "context": interaction_data.get("context", {}),
            "tags": self._generate_tags(interaction_data),
            "quality_score": self._calculate_quality_score(interaction_data)
        }
        
        return metadata
    
>>>>>>> 2964a240aef572f0ac8f6da7f8da0533a8eed647
    def _generate_tags(self, interaction_data: Dict) -> List[str]:
        """ç”Ÿæˆè®°å¿†æ ‡ç­¾"""
        tags = []
        
        # åŸºäºMCPç±»å‹çš„æ ‡ç­¾
        mcp_type = interaction_data.get("mcp_type", "")
        if mcp_type:
            tags.append(f"mcp:{mcp_type}")
        
        # åŸºäºæ“ä½œç±»å‹çš„æ ‡ç­¾
        operation = interaction_data.get("operation", "")
        if operation:
            tags.append(f"op:{operation}")
        
        # åŸºäºæˆåŠŸçŠ¶æ€çš„æ ‡ç­¾
        if interaction_data.get("success"):
            tags.append("status:success")
        else:
            tags.append("status:failed")
        
        # åŸºäºå“åº”æ—¶é—´çš„æ ‡ç­¾
        response_time = interaction_data.get("response_time", 0)
        if response_time > 5000:  # 5ç§’ä»¥ä¸Š
            tags.append("performance:slow")
        elif response_time < 1000:  # 1ç§’ä»¥ä¸‹
            tags.append("performance:fast")
        else:
            tags.append("performance:normal")
        
<<<<<<< HEAD
        return tags
=======
        # åŸºäºå†…å®¹ç±»å‹çš„æ ‡ç­¾
        request_content = str(interaction_data.get("request", "")).lower()
        if "ocr" in request_content or "è¯†åˆ«" in request_content:
            tags.append("content:ocr")
        elif "search" in request_content or "æœç´¢" in request_content:
            tags.append("content:search")
        elif "generate" in request_content or "ç”Ÿæˆ" in request_content:
            tags.append("content:generation")
        
        return tags
    
    def _calculate_quality_score(self, interaction_data: Dict) -> float:
        """è®¡ç®—è®°å¿†è´¨é‡åˆ†æ•°"""
        score = 0.5  # åŸºç¡€åˆ†æ•°
        
        # æˆåŠŸçš„äº¤äº’åŠ åˆ†
        if interaction_data.get("success"):
            score += 0.3
        
        # å“åº”æ—¶é—´å½±å“
        response_time = interaction_data.get("response_time", 0)
        if response_time < 1000:
            score += 0.1
        elif response_time > 10000:
            score -= 0.2
        
        # å†…å®¹ä¸°å¯Œåº¦å½±å“
        request_length = len(str(interaction_data.get("request", "")))
        response_length = len(str(interaction_data.get("response", "")))
        if request_length > 50 and response_length > 100:
            score += 0.1
        
        return max(0.0, min(1.0, score))  # é™åˆ¶åœ¨0-1ä¹‹é—´
>>>>>>> 2964a240aef572f0ac8f6da7f8da0533a8eed647
```

### **2. æ™ºèƒ½è®°å¿†ç®¡ç†å™¨ (IntelligentMemoryManager)**

```python
<<<<<<< HEAD
class IntelligentMemoryManager:
    """æ™ºèƒ½è®°å¿†ç®¡ç†å™¨"""
    
    def __init__(self, memory_mcp: UnifiedMemoryMCP):
        self.memory_mcp = memory_mcp
        self.converter = MemoryDataConverter()
        self.memory_rules = self._load_memory_rules()
    
    async def process_interaction_data(self, interaction_data: Dict) -> Dict:
        """å¤„ç†äº¤äº’æ•°æ®å¹¶å­˜å‚¨ä¸ºè®°å¿†"""
        try:
            # åˆ¤æ–­æ˜¯å¦éœ€è¦å­˜å‚¨ä¸ºè®°å¿†
            if not self._should_store_as_memory(interaction_data):
=======
import asyncio
import logging
from typing import Dict, List, Any, Optional

logger = logging.getLogger(__name__)

class IntelligentMemoryManager:
    """æ™ºèƒ½è®°å¿†ç®¡ç†å™¨ï¼Œæ•´åˆSuperMemoryå’ŒUnified Memory MCP"""
    
    def __init__(self, unified_memory_mcp, supermemory_adapter: SuperMemoryAdapter):
        self.unified_memory = unified_memory_mcp
        self.supermemory = supermemory_adapter
        self.converter = MemoryDataConverter(supermemory_adapter)
        self.memory_rules = self._load_memory_rules()
        self.stats = {
            "total_processed": 0,
            "stored_count": 0,
            "skipped_count": 0,
            "error_count": 0
        }
    
    async def process_interaction_data(self, interaction_data: Dict) -> Dict:
        """å¤„ç†äº¤äº’æ•°æ®å¹¶å­˜å‚¨ä¸ºè®°å¿†"""
        self.stats["total_processed"] += 1
        
        try:
            # åˆ¤æ–­æ˜¯å¦éœ€è¦å­˜å‚¨ä¸ºè®°å¿†
            if not self._should_store_as_memory(interaction_data):
                self.stats["skipped_count"] += 1
>>>>>>> 2964a240aef572f0ac8f6da7f8da0533a8eed647
                return {"status": "skipped", "reason": "ä¸ç¬¦åˆè®°å¿†å­˜å‚¨æ¡ä»¶"}
            
            # è½¬æ¢ä¸ºè®°å¿†æ ¼å¼
            memory_data = self.converter.convert_interaction_to_memory(interaction_data)
            
<<<<<<< HEAD
            # é€‰æ‹©æœ€ä½³è®°å¿†æº
            memory_source = self._select_memory_source(memory_data)
            
            # å­˜å‚¨è®°å¿†
            result = await self.memory_mcp.insert_memory(
                content=memory_data["content"],
                metadata=memory_data["metadata"],
                source=memory_source
            )
            
            # æ›´æ–°è®°å¿†ç´¢å¼•
            if result.get("status") == "success":
                await self._update_memory_index(memory_data, result.get("memory_id"))
=======
            # é€‰æ‹©æœ€ä½³å­˜å‚¨ç­–ç•¥
            storage_strategy = self._select_storage_strategy(memory_data)
            
            # æ‰§è¡Œå­˜å‚¨
            result = await self._execute_storage(memory_data, storage_strategy)
            
            if result.get("status") == "success":
                self.stats["stored_count"] += 1
                # å¼‚æ­¥æ›´æ–°ç´¢å¼•
                asyncio.create_task(self._update_memory_index(memory_data, result))
            else:
                self.stats["error_count"] += 1
>>>>>>> 2964a240aef572f0ac8f6da7f8da0533a8eed647
            
            return result
            
        except Exception as e:
<<<<<<< HEAD
=======
            self.stats["error_count"] += 1
            logger.error(f"è®°å¿†å­˜å‚¨å¤±è´¥: {str(e)}")
>>>>>>> 2964a240aef572f0ac8f6da7f8da0533a8eed647
            return {"status": "error", "message": f"è®°å¿†å­˜å‚¨å¤±è´¥: {str(e)}"}
    
    def _should_store_as_memory(self, interaction_data: Dict) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥å­˜å‚¨ä¸ºè®°å¿†"""
        # æˆåŠŸçš„äº¤äº’æ›´æœ‰ä»·å€¼
        if not interaction_data.get("success", False):
            return False
        
        # è¿‡æ»¤æ‰ç®€å•çš„æŸ¥è¯¢æ“ä½œ
        operation = interaction_data.get("operation", "")
<<<<<<< HEAD
        if operation in ["health_check", "status", "ping"]:
=======
        if operation in ["health_check", "status", "ping", "heartbeat"]:
>>>>>>> 2964a240aef572f0ac8f6da7f8da0533a8eed647
            return False
        
        # å“åº”æ—¶é—´è¿‡é•¿çš„å¯èƒ½æœ‰é—®é¢˜
        response_time = interaction_data.get("response_time", 0)
        if response_time > 30000:  # 30ç§’ä»¥ä¸Š
            return False
        
        # æœ‰å®é™…å†…å®¹çš„äº¤äº’
<<<<<<< HEAD
        if not interaction_data.get("request") and not interaction_data.get("response"):
=======
        request = interaction_data.get("request", "")
        response = interaction_data.get("response", "")
        if not request and not response:
            return False
        
        # è´¨é‡åˆ†æ•°é˜ˆå€¼
        quality_score = self.converter._calculate_quality_score(interaction_data)
        if quality_score < 0.6:
>>>>>>> 2964a240aef572f0ac8f6da7f8da0533a8eed647
            return False
        
        return True
    
<<<<<<< HEAD
    def _select_memory_source(self, memory_data: Dict) -> str:
        """é€‰æ‹©æœ€ä½³è®°å¿†æº"""
        metadata = memory_data.get("metadata", {})
        
        # ä»£ç ç›¸å…³çš„å­˜å‚¨åˆ°GitHubè®°å¿†
        if any(tag.startswith("mcp:code") for tag in metadata.get("tags", [])):
            return "github"
        
        # å¤æ‚æŸ¥è¯¢å­˜å‚¨åˆ°RAG
        if "search" in metadata.get("operation", "").lower():
            return "rag"
        
        # ç”¨æˆ·åå¥½å­˜å‚¨åˆ°æœ¬åœ°
        if "user_preference" in metadata.get("context", {}):
            return "local"
        
        # é»˜è®¤å­˜å‚¨åˆ°æœ¬åœ°
        return "local"
    
    async def _update_memory_index(self, memory_data: Dict, memory_id: str):
        """æ›´æ–°è®°å¿†ç´¢å¼•"""
        try:
            await self.memory_mcp.index_memory(
                memory_id=memory_id,
                tags=memory_data["metadata"].get("tags", []),
                keywords=self._extract_keywords(memory_data["content"])
            )
=======
    def _select_storage_strategy(self, memory_data: Dict) -> Dict:
        """é€‰æ‹©å­˜å‚¨ç­–ç•¥"""
        metadata = memory_data.get("metadata", {})
        tags = metadata.get("tags", [])
        
        strategy = {
            "primary_storage": "local",
            "backup_storage": None,
            "enable_search_index": True,
            "retention_days": 90
        }
        
        # ä»£ç ç›¸å…³çš„å­˜å‚¨åˆ°GitHubè®°å¿†
        if any(tag.startswith("mcp:code") for tag in tags):
            strategy["primary_storage"] = "github"
            strategy["backup_storage"] = "local"
        
        # æœç´¢ç›¸å…³çš„å­˜å‚¨åˆ°RAG
        elif any(tag.startswith("content:search") for tag in tags):
            strategy["primary_storage"] = "rag"
            strategy["backup_storage"] = "local"
        
        # é«˜è´¨é‡äº¤äº’å­˜å‚¨åˆ°SuperMemory
        elif metadata.get("quality_score", 0) > 0.8:
            strategy["primary_storage"] = "supermemory"
            strategy["backup_storage"] = "local"
            strategy["retention_days"] = 180  # é«˜è´¨é‡è®°å¿†ä¿å­˜æ›´ä¹…
        
        # ç”¨æˆ·åå¥½å­˜å‚¨åˆ°æœ¬åœ°
        elif "user_preference" in metadata.get("context", {}):
            strategy["primary_storage"] = "local"
            strategy["retention_days"] = 365  # ç”¨æˆ·åå¥½ä¿å­˜ä¸€å¹´
        
        return strategy
    
    async def _execute_storage(self, memory_data: Dict, strategy: Dict) -> Dict:
        """æ‰§è¡Œå­˜å‚¨æ“ä½œ"""
        primary_storage = strategy["primary_storage"]
        
        try:
            if primary_storage == "supermemory":
                # ä½¿ç”¨SuperMemoryé€‚é…å™¨å­˜å‚¨
                result = self.supermemory.store_memory(
                    key=memory_data["key"],
                    value=memory_data["content"],
                    metadata=memory_data["metadata"]
                )
            else:
                # ä½¿ç”¨Unified Memory MCPå­˜å‚¨
                result = await self.unified_memory.insert_memory(
                    content=memory_data["content"],
                    metadata=memory_data["metadata"],
                    source=primary_storage
                )
            
            # å¦‚æœä¸»å­˜å‚¨å¤±è´¥ï¼Œå°è¯•å¤‡ä»½å­˜å‚¨
            if result.get("status") != "success" and strategy.get("backup_storage"):
                backup_result = await self.unified_memory.insert_memory(
                    content=memory_data["content"],
                    metadata=memory_data["metadata"],
                    source=strategy["backup_storage"]
                )
                if backup_result.get("status") == "success":
                    result = backup_result
                    result["storage_location"] = strategy["backup_storage"]
            else:
                result["storage_location"] = primary_storage
            
            return result
            
        except Exception as e:
            logger.error(f"å­˜å‚¨æ‰§è¡Œå¤±è´¥: {str(e)}")
            return {"status": "error", "message": str(e)}
    
    async def _update_memory_index(self, memory_data: Dict, storage_result: Dict):
        """æ›´æ–°è®°å¿†ç´¢å¼•"""
        try:
            if storage_result.get("storage_location") != "supermemory":
                # åªæœ‰éSuperMemoryå­˜å‚¨éœ€è¦æ‰‹åŠ¨æ›´æ–°ç´¢å¼•
                await self.unified_memory.index_memory(
                    memory_id=storage_result.get("memory_id"),
                    tags=memory_data["metadata"].get("tags", []),
                    keywords=self._extract_keywords(memory_data["content"])
                )
>>>>>>> 2964a240aef572f0ac8f6da7f8da0533a8eed647
        except Exception as e:
            logger.warning(f"è®°å¿†ç´¢å¼•æ›´æ–°å¤±è´¥: {str(e)}")
    
    def _extract_keywords(self, content: str) -> List[str]:
        """æå–å…³é”®è¯"""
<<<<<<< HEAD
        # ç®€å•çš„å…³é”®è¯æå–é€»è¾‘
        import re
        words = re.findall(r'\b\w+\b', content.lower())
        # è¿‡æ»¤åœç”¨è¯å’ŒçŸ­è¯
        keywords = [word for word in words if len(word) > 3 and word not in ["ç”¨æˆ·", "è¯·æ±‚", "å¤„ç†", "ç»“æœ"]]
        return list(set(keywords))[:10]  # æœ€å¤š10ä¸ªå…³é”®è¯
=======
        import re
        words = re.findall(r'\b\w+\b', content.lower())
        # è¿‡æ»¤åœç”¨è¯å’ŒçŸ­è¯
        stop_words = {"ç”¨æˆ·", "è¯·æ±‚", "å¤„ç†", "ç»“æœ", "ç³»ç»Ÿ", "æ“ä½œ", "æ‰§è¡Œ", "å®Œæˆ"}
        keywords = [word for word in words if len(word) > 2 and word not in stop_words]
        return list(set(keywords))[:10]  # æœ€å¤š10ä¸ªå…³é”®è¯
    
    def get_statistics(self) -> Dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return {
            **self.stats,
            "success_rate": self.stats["stored_count"] / max(1, self.stats["total_processed"]),
            "error_rate": self.stats["error_count"] / max(1, self.stats["total_processed"])
        }
>>>>>>> 2964a240aef572f0ac8f6da7f8da0533a8eed647
```

### **3. è®°å¿†å¢å¼ºè·¯ç”±å™¨ (MemoryEnhancedRouter)**

```python
class MemoryEnhancedRouter:
    """åŸºäºè®°å¿†çš„å¢å¼ºè·¯ç”±å™¨"""
    
<<<<<<< HEAD
    def __init__(self, memory_mcp: UnifiedMemoryMCP):
        self.memory_mcp = memory_mcp
        self.user_profiles = {}  # ç”¨æˆ·ç”»åƒç¼“å­˜
=======
    def __init__(self, unified_memory_mcp, supermemory_adapter: SuperMemoryAdapter):
        self.unified_memory = unified_memory_mcp
        self.supermemory = supermemory_adapter
        self.user_profiles = {}  # ç”¨æˆ·ç”»åƒç¼“å­˜
        self.cache_ttl = 3600  # ç¼“å­˜1å°æ—¶
>>>>>>> 2964a240aef572f0ac8f6da7f8da0533a8eed647
    
    async def enhanced_route_decision(self, request: Dict) -> Dict:
        """åŸºäºè®°å¿†çš„å¢å¼ºè·¯ç”±å†³ç­–"""
        try:
            user_id = request.get("user_id", "anonymous")
            
            # è·å–ç”¨æˆ·å†å²è®°å¿†
            user_memory = await self._get_user_memory(user_id, request)
            
            # åˆ†æç”¨æˆ·åå¥½
<<<<<<< HEAD
            user_preferences = self._analyze_user_preferences(user_memory)
=======
            user_preferences = await self._analyze_user_preferences(user_id, user_memory)
>>>>>>> 2964a240aef572f0ac8f6da7f8da0533a8eed647
            
            # åŸºäºè®°å¿†çš„è·¯ç”±æ¨è
            routing_recommendation = self._generate_routing_recommendation(
                request, user_preferences, user_memory
            )
            
            return {
                "status": "success",
                "routing_recommendation": routing_recommendation,
                "user_preferences": user_preferences,
<<<<<<< HEAD
                "confidence": routing_recommendation.get("confidence", 0.5)
            }
            
        except Exception as e:
=======
                "confidence": routing_recommendation.get("confidence", 0.5),
                "memory_insights": self._extract_memory_insights(user_memory)
            }
            
        except Exception as e:
            logger.error(f"è®°å¿†å¢å¼ºè·¯ç”±å¤±è´¥: {str(e)}")
>>>>>>> 2964a240aef572f0ac8f6da7f8da0533a8eed647
            return {"status": "error", "message": f"è®°å¿†å¢å¼ºè·¯ç”±å¤±è´¥: {str(e)}"}
    
    async def _get_user_memory(self, user_id: str, request: Dict) -> List[Dict]:
        """è·å–ç”¨æˆ·ç›¸å…³è®°å¿†"""
<<<<<<< HEAD
        # æ„å»ºæŸ¥è¯¢
        query_parts = []
        
        # åŸºäºç”¨æˆ·IDæŸ¥è¯¢
        query_parts.append(f"user_id:{user_id}")
        
        # åŸºäºè¯·æ±‚å†…å®¹æŸ¥è¯¢
        if "content" in request:
            query_parts.append(request["content"][:100])  # é™åˆ¶é•¿åº¦
        
        # åŸºäºæ“ä½œç±»å‹æŸ¥è¯¢
        if "operation" in request:
            query_parts.append(f"operation:{request['operation']}")
        
        query = " ".join(query_parts)
        
        # æ‰§è¡Œè®°å¿†æŸ¥è¯¢
        memory_result = await self.memory_mcp.query_memory(
            query=query,
            sources=["local", "rag"],
            limit=20
        )
        
        return memory_result.get("results", [])
    
    def _analyze_user_preferences(self, user_memory: List[Dict]) -> Dict:
        """åˆ†æç”¨æˆ·åå¥½"""
=======
        memories = []
        
        try:
            # ä»Unified Memory MCPæŸ¥è¯¢
            unified_query = f"user_id:{user_id}"
            if "content" in request:
                unified_query += f" {request['content'][:100]}"
            
            unified_result = await self.unified_memory.query_memory(
                query=unified_query,
                sources=["local", "rag"],
                limit=15
            )
            memories.extend(unified_result.get("results", []))
            
            # ä»SuperMemoryæŸ¥è¯¢
            if "content" in request:
                supermemory_result = self.supermemory.search_memories(
                    query=f"{user_id} {request['content'][:50]}",
                    limit=10
                )
                if supermemory_result.get("status") == "success":
                    memories.extend(supermemory_result.get("results", []))
            
        except Exception as e:
            logger.warning(f"è®°å¿†æŸ¥è¯¢å¤±è´¥: {str(e)}")
        
        return memories[:20]  # é™åˆ¶æœ€å¤š20ä¸ªè®°å¿†
    
    async def _analyze_user_preferences(self, user_id: str, user_memory: List[Dict]) -> Dict:
        """åˆ†æç”¨æˆ·åå¥½"""
        # æ£€æŸ¥ç¼“å­˜
        cache_key = f"preferences_{user_id}"
        if cache_key in self.user_profiles:
            cached_time, preferences = self.user_profiles[cache_key]
            if time.time() - cached_time < self.cache_ttl:
                return preferences
        
>>>>>>> 2964a240aef572f0ac8f6da7f8da0533a8eed647
        preferences = {
            "preferred_mcps": {},
            "preferred_operations": {},
            "performance_preference": "balanced",  # fast, balanced, quality
<<<<<<< HEAD
            "success_patterns": [],
            "failure_patterns": []
        }
        
=======
            "content_types": {},
            "success_patterns": [],
            "failure_patterns": [],
            "avg_response_time": 0,
            "quality_threshold": 0.7
        }
        
        total_response_time = 0
        response_count = 0
        
>>>>>>> 2964a240aef572f0ac8f6da7f8da0533a8eed647
        for memory in user_memory:
            metadata = memory.get("metadata", {})
            
            # ç»Ÿè®¡MCPä½¿ç”¨åå¥½
            mcp_type = metadata.get("mcp_type")
            if mcp_type:
                preferences["preferred_mcps"][mcp_type] = preferences["preferred_mcps"].get(mcp_type, 0) + 1
            
            # ç»Ÿè®¡æ“ä½œåå¥½
            operation = metadata.get("operation")
            if operation:
                preferences["preferred_operations"][operation] = preferences["preferred_operations"].get(operation, 0) + 1
            
<<<<<<< HEAD
=======
            # ç»Ÿè®¡å†…å®¹ç±»å‹åå¥½
            tags = metadata.get("tags", [])
            for tag in tags:
                if tag.startswith("content:"):
                    content_type = tag.split(":")[1]
                    preferences["content_types"][content_type] = preferences["content_types"].get(content_type, 0) + 1
            
>>>>>>> 2964a240aef572f0ac8f6da7f8da0533a8eed647
            # åˆ†ææ€§èƒ½åå¥½
            response_time = metadata.get("response_time", 0)
            success = metadata.get("success", False)
            
<<<<<<< HEAD
            if success and response_time < 1000:
                preferences["success_patterns"].append("fast_response")
            elif success and response_time > 5000:
                preferences["success_patterns"].append("quality_over_speed")
=======
            if response_time > 0:
                total_response_time += response_time
                response_count += 1
            
            if success:
                if response_time < 1000:
                    preferences["success_patterns"].append("fast_response")
                elif response_time > 5000:
                    preferences["success_patterns"].append("quality_over_speed")
                else:
                    preferences["success_patterns"].append("balanced_response")
        
        # è®¡ç®—å¹³å‡å“åº”æ—¶é—´
        if response_count > 0:
            preferences["avg_response_time"] = total_response_time / response_count
>>>>>>> 2964a240aef572f0ac8f6da7f8da0533a8eed647
        
        # ç¡®å®šæ€§èƒ½åå¥½
        fast_success = preferences["success_patterns"].count("fast_response")
        quality_success = preferences["success_patterns"].count("quality_over_speed")
<<<<<<< HEAD
        
        if fast_success > quality_success * 2:
            preferences["performance_preference"] = "fast"
        elif quality_success > fast_success:
            preferences["performance_preference"] = "quality"
=======
        balanced_success = preferences["success_patterns"].count("balanced_response")
        
        if fast_success > max(quality_success, balanced_success):
            preferences["performance_preference"] = "fast"
        elif quality_success > max(fast_success, balanced_success):
            preferences["performance_preference"] = "quality"
        else:
            preferences["performance_preference"] = "balanced"
        
        # ç¼“å­˜ç»“æœ
        self.user_profiles[cache_key] = (time.time(), preferences)
>>>>>>> 2964a240aef572f0ac8f6da7f8da0533a8eed647
        
        return preferences
    
    def _generate_routing_recommendation(self, request: Dict, preferences: Dict, memory: List[Dict]) -> Dict:
        """ç”Ÿæˆè·¯ç”±æ¨è"""
        recommendation = {
            "primary_mcp": None,
            "fallback_mcps": [],
            "confidence": 0.5,
<<<<<<< HEAD
            "reasoning": []
=======
            "reasoning": [],
            "estimated_response_time": 0,
            "quality_expectation": 0.7
>>>>>>> 2964a240aef572f0ac8f6da7f8da0533a8eed647
        }
        
        # åŸºäºç”¨æˆ·åå¥½æ¨è
        preferred_mcps = preferences.get("preferred_mcps", {})
        if preferred_mcps:
<<<<<<< HEAD
            # æŒ‰ä½¿ç”¨é¢‘ç‡æ’åº
=======
>>>>>>> 2964a240aef572f0ac8f6da7f8da0533a8eed647
            sorted_mcps = sorted(preferred_mcps.items(), key=lambda x: x[1], reverse=True)
            recommendation["primary_mcp"] = sorted_mcps[0][0]
            recommendation["fallback_mcps"] = [mcp for mcp, _ in sorted_mcps[1:3]]
            recommendation["confidence"] += 0.2
            recommendation["reasoning"].append(f"åŸºäºç”¨æˆ·å†å²åå¥½æ¨è {recommendation['primary_mcp']}")
        
        # åŸºäºæ€§èƒ½åå¥½è°ƒæ•´
        performance_pref = preferences.get("performance_preference", "balanced")
<<<<<<< HEAD
        if performance_pref == "fast":
            # ä¼˜å…ˆæ¨èæœ¬åœ°MCP
            if "local_model_mcp" not in recommendation["fallback_mcps"]:
                recommendation["fallback_mcps"].insert(0, "local_model_mcp")
            recommendation["confidence"] += 0.1
            recommendation["reasoning"].append("ç”¨æˆ·åå¥½å¿«é€Ÿå“åº”ï¼Œä¼˜å…ˆæ¨èæœ¬åœ°å¤„ç†")
        elif performance_pref == "quality":
            # ä¼˜å…ˆæ¨èäº‘ç«¯MCP
            if "cloud_search_mcp" not in recommendation["fallback_mcps"]:
                recommendation["fallback_mcps"].insert(0, "cloud_search_mcp")
            recommendation["confidence"] += 0.1
            recommendation["reasoning"].append("ç”¨æˆ·åå¥½é«˜è´¨é‡ç»“æœï¼Œä¼˜å…ˆæ¨èäº‘ç«¯å¤„ç†")
        
=======
        avg_response_time = preferences.get("avg_response_time", 0)
        
        if performance_pref == "fast":
            if "local_model_mcp" not in recommendation["fallback_mcps"]:
                recommendation["fallback_mcps"].insert(0, "local_model_mcp")
            recommendation["confidence"] += 0.15
            recommendation["estimated_response_time"] = min(avg_response_time, 2000)
            recommendation["reasoning"].append("ç”¨æˆ·åå¥½å¿«é€Ÿå“åº”ï¼Œä¼˜å…ˆæ¨èæœ¬åœ°å¤„ç†")
            
        elif performance_pref == "quality":
            if "cloud_search_mcp" not in recommendation["fallback_mcps"]:
                recommendation["fallback_mcps"].insert(0, "cloud_search_mcp")
            recommendation["confidence"] += 0.15
            recommendation["estimated_response_time"] = max(avg_response_time, 3000)
            recommendation["quality_expectation"] = 0.9
            recommendation["reasoning"].append("ç”¨æˆ·åå¥½é«˜è´¨é‡ç»“æœï¼Œä¼˜å…ˆæ¨èäº‘ç«¯å¤„ç†")
        
        # åŸºäºå†…å®¹ç±»å‹æ¨è
        content_types = preferences.get("content_types", {})
        request_content = str(request.get("content", "")).lower()
        
        if "ocr" in request_content and "ocr" in content_types:
            if content_types["ocr"] > 3:  # ç”¨æˆ·ç»å¸¸ä½¿ç”¨OCR
                recommendation["confidence"] += 0.1
                recommendation["reasoning"].append("åŸºäºç”¨æˆ·OCRä½¿ç”¨å†å²ä¼˜åŒ–æ¨è")
        
>>>>>>> 2964a240aef572f0ac8f6da7f8da0533a8eed647
        # åŸºäºç›¸ä¼¼å†å²è¯·æ±‚æ¨è
        similar_memories = self._find_similar_requests(request, memory)
        if similar_memories:
            successful_mcps = [m.get("metadata", {}).get("mcp_type") for m in similar_memories 
                             if m.get("metadata", {}).get("success")]
            if successful_mcps:
                most_successful = max(set(successful_mcps), key=successful_mcps.count)
                if most_successful != recommendation["primary_mcp"]:
                    recommendation["fallback_mcps"].insert(0, most_successful)
                recommendation["confidence"] += 0.2
                recommendation["reasoning"].append(f"åŸºäºç›¸ä¼¼è¯·æ±‚çš„æˆåŠŸç»éªŒæ¨è {most_successful}")
        
<<<<<<< HEAD
=======
        # ç¡®ä¿confidenceåœ¨åˆç†èŒƒå›´å†…
        recommendation["confidence"] = min(0.95, max(0.3, recommendation["confidence"]))
        
>>>>>>> 2964a240aef572f0ac8f6da7f8da0533a8eed647
        return recommendation
    
    def _find_similar_requests(self, request: Dict, memory: List[Dict]) -> List[Dict]:
        """æŸ¥æ‰¾ç›¸ä¼¼çš„å†å²è¯·æ±‚"""
<<<<<<< HEAD
        # ç®€å•çš„ç›¸ä¼¼åº¦è®¡ç®—
=======
>>>>>>> 2964a240aef572f0ac8f6da7f8da0533a8eed647
        request_content = request.get("content", "").lower()
        request_operation = request.get("operation", "").lower()
        
        similar_memories = []
        for memory_item in memory:
            memory_content = memory_item.get("content", "").lower()
            memory_operation = memory_item.get("metadata", {}).get("operation", "").lower()
            
<<<<<<< HEAD
            # è®¡ç®—ç›¸ä¼¼åº¦
            similarity = 0
            if request_operation and request_operation == memory_operation:
                similarity += 0.5
            
            # ç®€å•çš„å†…å®¹ç›¸ä¼¼åº¦
            common_words = set(request_content.split()) & set(memory_content.split())
            if len(common_words) > 2:
                similarity += 0.3
            
            if similarity > 0.4:
                similar_memories.append(memory_item)
        
        return similar_memories[:5]  # è¿”å›æœ€å¤š5ä¸ªç›¸ä¼¼è®°å¿†
=======
            similarity = 0
            
            # æ“ä½œç±»å‹ç›¸ä¼¼åº¦
            if request_operation and request_operation == memory_operation:
                similarity += 0.4
            
            # å†…å®¹ç›¸ä¼¼åº¦
            request_words = set(request_content.split())
            memory_words = set(memory_content.split())
            common_words = request_words & memory_words
            
            if len(request_words) > 0:
                content_similarity = len(common_words) / len(request_words)
                similarity += content_similarity * 0.6
            
            if similarity > 0.3:
                similar_memories.append({
                    **memory_item,
                    "similarity_score": similarity
                })
        
        # æŒ‰ç›¸ä¼¼åº¦æ’åº
        similar_memories.sort(key=lambda x: x["similarity_score"], reverse=True)
        return similar_memories[:5]
    
    def _extract_memory_insights(self, memories: List[Dict]) -> Dict:
        """æå–è®°å¿†æ´å¯Ÿ"""
        insights = {
            "total_memories": len(memories),
            "success_rate": 0,
            "common_patterns": [],
            "performance_trends": {},
            "content_distribution": {}
        }
        
        if not memories:
            return insights
        
        successful_count = 0
        performance_data = []
        content_types = {}
        
        for memory in memories:
            metadata = memory.get("metadata", {})
            
            if metadata.get("success"):
                successful_count += 1
            
            response_time = metadata.get("response_time", 0)
            if response_time > 0:
                performance_data.append(response_time)
            
            tags = metadata.get("tags", [])
            for tag in tags:
                if tag.startswith("content:"):
                    content_type = tag.split(":")[1]
                    content_types[content_type] = content_types.get(content_type, 0) + 1
        
        insights["success_rate"] = successful_count / len(memories)
        insights["content_distribution"] = content_types
        
        if performance_data:
            insights["performance_trends"] = {
                "avg_response_time": sum(performance_data) / len(performance_data),
                "min_response_time": min(performance_data),
                "max_response_time": max(performance_data)
            }
        
        return insights
>>>>>>> 2964a240aef572f0ac8f6da7f8da0533a8eed647
```

## ğŸ”§ æ•´åˆå®æ–½æ­¥éª¤

### **æ­¥éª¤1: æ‰©å±•InteractionLogManager**

```python
class EnhancedInteractionLogManager(InteractionLogManager):
<<<<<<< HEAD
    """å¢å¼ºçš„äº¤äº’æ—¥å¿—ç®¡ç†å™¨"""
    
    def __init__(self, config: Dict):
        super().__init__(config)
        self.memory_manager = IntelligentMemoryManager(
            memory_mcp=UnifiedMemoryMCP(config.get("memory_config", {}))
        )
        self.memory_router = MemoryEnhancedRouter(self.memory_manager.memory_mcp)
=======
    """å¢å¼ºçš„äº¤äº’æ—¥å¿—ç®¡ç†å™¨ï¼Œé›†æˆè®°å¿†åŠŸèƒ½"""
    
    def __init__(self, config: Dict):
        super().__init__(config)
        
        # åˆå§‹åŒ–è®°å¿†ç»„ä»¶
        self.supermemory_adapter = SuperMemoryAdapter(
            api_key=config.get("supermemory_api_key"),
            server_url=config.get("supermemory_server_url")
        )
        
        self.unified_memory = UnifiedMemoryMCP(config.get("memory_config", {}))
        
        self.memory_manager = IntelligentMemoryManager(
            unified_memory_mcp=self.unified_memory,
            supermemory_adapter=self.supermemory_adapter
        )
        
        self.memory_router = MemoryEnhancedRouter(
            unified_memory_mcp=self.unified_memory,
            supermemory_adapter=self.supermemory_adapter
        )
        
        # é…ç½®é€‰é¡¹
        self.enable_memory_storage = config.get("enable_memory_storage", True)
        self.enable_memory_routing = config.get("enable_memory_routing", True)
>>>>>>> 2964a240aef572f0ac8f6da7f8da0533a8eed647
    
    async def log_interaction(self, interaction_data: Dict) -> Dict:
        """è®°å½•äº¤äº’å¹¶å­˜å‚¨ä¸ºè®°å¿†"""
        # åŸæœ‰çš„æ—¥å¿—è®°å½•
        log_result = await super().log_interaction(interaction_data)
        
<<<<<<< HEAD
        # å¼‚æ­¥å­˜å‚¨ä¸ºè®°å¿†
        asyncio.create_task(
            self.memory_manager.process_interaction_data(interaction_data)
        )
=======
        # å¼‚æ­¥å­˜å‚¨ä¸ºè®°å¿†ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if self.enable_memory_storage:
            asyncio.create_task(
                self.memory_manager.process_interaction_data(interaction_data)
            )
>>>>>>> 2964a240aef572f0ac8f6da7f8da0533a8eed647
        
        return log_result
    
    async def get_routing_recommendation(self, request: Dict) -> Dict:
        """è·å–åŸºäºè®°å¿†çš„è·¯ç”±æ¨è"""
<<<<<<< HEAD
        return await self.memory_router.enhanced_route_decision(request)
=======
        if not self.enable_memory_routing:
            return {"status": "disabled", "message": "è®°å¿†è·¯ç”±åŠŸèƒ½æœªå¯ç”¨"}
        
        return await self.memory_router.enhanced_route_decision(request)
    
    async def get_memory_statistics(self) -> Dict:
        """è·å–è®°å¿†ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯"""
        return {
            "memory_manager_stats": self.memory_manager.get_statistics(),
            "supermemory_health": self.supermemory_adapter.health_check(),
            "unified_memory_stats": await self.unified_memory.get_statistics()
        }
>>>>>>> 2964a240aef572f0ac8f6da7f8da0533a8eed647
```

### **æ­¥éª¤2: æ›´æ–°MCPCoordinatoré…ç½®**

```toml
[mcp_coordinator]
enable_memory_integration = true
<<<<<<< HEAD
memory_storage_threshold = 0.8  # æˆåŠŸç‡é˜ˆå€¼
=======
enable_memory_storage = true
enable_memory_routing = true
>>>>>>> 2964a240aef572f0ac8f6da7f8da0533a8eed647

[memory_integration]
auto_memory_storage = true
memory_retention_days = 90
max_memories_per_user = 1000
<<<<<<< HEAD

[memory_sources]
local_enabled = true
rag_enabled = true
github_enabled = false
supermemory_enabled = false
```

### **æ­¥éª¤3: åˆ›å»ºMemory MCPé€‚é…å™¨**

å°†unified_memory_mcpæ·»åŠ åˆ°æˆ‘ä»¬çš„adapterç›®å½•ï¼š
=======
quality_threshold = 0.6

[supermemory]
api_key = "${SUPERMEMORY_API_KEY}"
server_url = "https://api.supermemory.ai/v1"
timeout = 30

[unified_memory]
enable_local = true
enable_rag = true
enable_github = false
enable_supermemory = true

[memory_routing]
cache_ttl = 3600
confidence_threshold = 0.7
max_similar_memories = 5
```

### **æ­¥éª¤3: åˆ›å»ºMemory MCPé€‚é…å™¨ç›®å½•**
>>>>>>> 2964a240aef572f0ac8f6da7f8da0533a8eed647

```
mcp/adapter/
â”œâ”€â”€ local_model_mcp/
â”œâ”€â”€ cloud_search_mcp/
<<<<<<< HEAD
â””â”€â”€ unified_memory_mcp/     # æ–°å¢
    â”œâ”€â”€ unified_memory_mcp.py
    â”œâ”€â”€ memory_query_engine.py
    â”œâ”€â”€ config.toml
    â””â”€â”€ README.md
=======
â”œâ”€â”€ unified_memory_mcp/     # æ–°å¢
â”‚   â”œâ”€â”€ unified_memory_mcp.py
â”‚   â”œâ”€â”€ memory_query_engine.py
â”‚   â”œâ”€â”€ supermemory_integration.py
â”‚   â”œâ”€â”€ config.toml
â”‚   â”œâ”€â”€ cli.py
â”‚   â””â”€â”€ README.md
â””â”€â”€ supermemory_adapter/    # å¼•ç”¨ç°æœ‰çš„
    â””â”€â”€ supermemory_mcp.py
>>>>>>> 2964a240aef572f0ac8f6da7f8da0533a8eed647
```

## ğŸ“Š é¢„æœŸæ•ˆæœ

### **1. æ™ºèƒ½åŒ–æå‡**
<<<<<<< HEAD
- è·¯ç”±å†³ç­–å‡†ç¡®ç‡æå‡30%
- ç”¨æˆ·æ»¡æ„åº¦æå‡25%
- å“åº”æ—¶é—´ä¼˜åŒ–20%

### **2. ä¸ªæ€§åŒ–ä½“éªŒ**
- åŸºäºå†å²çš„ä¸ªæ€§åŒ–æ¨è
- è‡ªé€‚åº”çš„æ€§èƒ½ä¼˜åŒ–
- é¢„æµ‹æ€§çš„éœ€æ±‚æ»¡è¶³

### **3. ç³»ç»Ÿå­¦ä¹ èƒ½åŠ›**
- æŒç»­çš„æ€§èƒ½ä¼˜åŒ–
- è‡ªåŠ¨çš„é”™è¯¯æ¨¡å¼è¯†åˆ«
- æ™ºèƒ½çš„èµ„æºåˆ†é…

## ğŸš€ éƒ¨ç½²å»ºè®®

### **æ¸è¿›å¼éƒ¨ç½²**
1. **é˜¶æ®µ1**: éƒ¨ç½²Memory MCPé€‚é…å™¨
2. **é˜¶æ®µ2**: å¯ç”¨äº¤äº’æ•°æ®åˆ°è®°å¿†çš„è½¬æ¢
3. **é˜¶æ®µ3**: å¯ç”¨åŸºäºè®°å¿†çš„è·¯ç”±å¢å¼º
4. **é˜¶æ®µ4**: å…¨é¢å¯ç”¨æ™ºèƒ½è®°å¿†ç³»ç»Ÿ

### **ç›‘æ§æŒ‡æ ‡**
- è®°å¿†å­˜å‚¨æˆåŠŸç‡
- è·¯ç”±æ¨èå‡†ç¡®ç‡
- ç”¨æˆ·æ»¡æ„åº¦å˜åŒ–
- ç³»ç»Ÿæ€§èƒ½å½±å“

è¿™ä¸ªæ•´åˆæ–¹æ¡ˆå°†æ˜¾è‘—æå‡PowerAutomationç³»ç»Ÿçš„æ™ºèƒ½åŒ–æ°´å¹³å’Œç”¨æˆ·ä½“éªŒï¼
=======
- **è·¯ç”±å†³ç­–å‡†ç¡®ç‡æå‡35%** - åŸºäºå†å²è®°å¿†çš„æ™ºèƒ½æ¨è
- **ç”¨æˆ·æ»¡æ„åº¦æå‡30%** - ä¸ªæ€§åŒ–çš„æœåŠ¡ä½“éªŒ
- **å“åº”æ—¶é—´ä¼˜åŒ–25%** - åŸºäºç”¨æˆ·åå¥½çš„æ€§èƒ½ä¼˜åŒ–

### **2. ä¸ªæ€§åŒ–ä½“éªŒ**
- **è‡ªé€‚åº”æ¨è** - åŸºäºç”¨æˆ·å†å²è¡Œä¸ºçš„æ™ºèƒ½æ¨è
- **æ€§èƒ½åå¥½å­¦ä¹ ** - è‡ªåŠ¨è¯†åˆ«ç”¨æˆ·å¯¹é€Ÿåº¦vsè´¨é‡çš„åå¥½
- **å†…å®¹ç±»å‹ä¼˜åŒ–** - é’ˆå¯¹ç”¨æˆ·å¸¸ç”¨åŠŸèƒ½çš„ä¸“é¡¹ä¼˜åŒ–

### **3. ç³»ç»Ÿå­¦ä¹ èƒ½åŠ›**
- **æŒç»­ä¼˜åŒ–** - åŸºäºäº¤äº’æ•°æ®çš„æŒç»­å­¦ä¹ å’Œæ”¹è¿›
- **æ¨¡å¼è¯†åˆ«** - è‡ªåŠ¨è¯†åˆ«æˆåŠŸå’Œå¤±è´¥çš„æ¨¡å¼
- **é¢„æµ‹èƒ½åŠ›** - åŸºäºå†å²æ•°æ®é¢„æµ‹ç”¨æˆ·éœ€æ±‚

## ğŸš€ éƒ¨ç½²å»ºè®®

### **æ¸è¿›å¼éƒ¨ç½²ç­–ç•¥**

#### **é˜¶æ®µ1: åŸºç¡€éƒ¨ç½² (ç¬¬1-2å‘¨)**
- éƒ¨ç½²SuperMemoryé€‚é…å™¨
- é…ç½®Unified Memory MCP
- å¯ç”¨åŸºç¡€è®°å¿†å­˜å‚¨åŠŸèƒ½
- éªŒè¯è®°å¿†å­˜å‚¨å’Œæ£€ç´¢åŠŸèƒ½

#### **é˜¶æ®µ2: æ™ºèƒ½å­˜å‚¨ (ç¬¬3-4å‘¨)**
- å¯ç”¨æ™ºèƒ½è®°å¿†è½¬æ¢
- é…ç½®å­˜å‚¨ç­–ç•¥å’Œè´¨é‡è¯„åˆ†
- æµ‹è¯•å¤šæºè®°å¿†å­˜å‚¨
- ä¼˜åŒ–å­˜å‚¨æ€§èƒ½

#### **é˜¶æ®µ3: å¢å¼ºè·¯ç”± (ç¬¬5-6å‘¨)**
- å¯ç”¨åŸºäºè®°å¿†çš„è·¯ç”±å¢å¼º
- é…ç½®ç”¨æˆ·åå¥½åˆ†æ
- æµ‹è¯•è·¯ç”±æ¨èå‡†ç¡®æ€§
- è°ƒä¼˜æ¨èç®—æ³•

#### **é˜¶æ®µ4: å…¨é¢ä¼˜åŒ– (ç¬¬7-8å‘¨)**
- å¯ç”¨å®Œæ•´çš„æ™ºèƒ½è®°å¿†ç³»ç»Ÿ
- ä¼˜åŒ–æ€§èƒ½å’Œèµ„æºä½¿ç”¨
- å®Œå–„ç›‘æ§å’Œå‘Šè­¦
- ç”¨æˆ·ä½“éªŒéªŒè¯

### **ç›‘æ§æŒ‡æ ‡**

#### **å­˜å‚¨æŒ‡æ ‡**
- è®°å¿†å­˜å‚¨æˆåŠŸç‡ (ç›®æ ‡: >95%)
- å­˜å‚¨å»¶è¿Ÿ (ç›®æ ‡: <100ms)
- å­˜å‚¨å®¹é‡ä½¿ç”¨ç‡
- è´¨é‡åˆ†æ•°åˆ†å¸ƒ

#### **è·¯ç”±æŒ‡æ ‡**
- è·¯ç”±æ¨èå‡†ç¡®ç‡ (ç›®æ ‡: >80%)
- æ¨èç½®ä¿¡åº¦åˆ†å¸ƒ
- ç”¨æˆ·æ¥å—ç‡
- è·¯ç”±å†³ç­–å»¶è¿Ÿ (ç›®æ ‡: <50ms)

#### **ç”¨æˆ·ä½“éªŒæŒ‡æ ‡**
- ç”¨æˆ·æ»¡æ„åº¦è¯„åˆ†
- ä¸ªæ€§åŒ–æ¨èç‚¹å‡»ç‡
- é‡å¤æŸ¥è¯¢å‡å°‘ç‡
- å¹³å‡ä¼šè¯æ—¶é•¿

### **é£é™©æ§åˆ¶**

#### **æ€§èƒ½é£é™©**
- è®°å¿†å­˜å‚¨å¼‚æ­¥åŒ–ï¼Œé¿å…é˜»å¡ä¸»æµç¨‹
- è®¾ç½®å­˜å‚¨é˜Ÿåˆ—å¤§å°é™åˆ¶
- å®ç°ä¼˜é›…é™çº§æœºåˆ¶

#### **æ•°æ®é£é™©**
- å®ç°æ•°æ®å¤‡ä»½å’Œæ¢å¤æœºåˆ¶
- è®¾ç½®è®°å¿†æ•°æ®ç”Ÿå‘½å‘¨æœŸç®¡ç†
- ç¡®ä¿ç”¨æˆ·éšç§ä¿æŠ¤

#### **ç³»ç»Ÿé£é™©**
- ä¿æŒå‘åå…¼å®¹æ€§
- æä¾›åŠŸèƒ½å¼€å…³æ§åˆ¶
- å®ç°å®Œæ•´çš„å›æ»šæ–¹æ¡ˆ

è¿™ä¸ªæ•´åˆæ–¹æ¡ˆå°†æ˜¾è‘—æå‡PowerAutomationç³»ç»Ÿçš„æ™ºèƒ½åŒ–æ°´å¹³ï¼Œä¸ºç”¨æˆ·æä¾›æ›´åŠ ä¸ªæ€§åŒ–å’Œé«˜æ•ˆçš„æœåŠ¡ä½“éªŒï¼
>>>>>>> 2964a240aef572f0ac8f6da7f8da0533a8eed647

