# Workflowè®¾è®¡å’Œé…ç½®æŒ‡å—

## ğŸ¯ Workflowè®¾è®¡åŸåˆ™

### **1. é…ç½®é©±åŠ¨çš„å·¥ä½œæµ**
æ‰€æœ‰workflowéƒ½åº”è¯¥é€šè¿‡é…ç½®æ–‡ä»¶å®šä¹‰æµç¨‹ï¼Œè€Œä¸æ˜¯ç¡¬ç¼–ç é€»è¾‘ã€‚

### **2. Adapterå¤ç”¨ä¼˜å…ˆ**
ä¼˜å…ˆä½¿ç”¨ç°æœ‰çš„adapter (local_model_mcp, cloud_search_mcp)ï¼Œé¿å…é‡å¤å®ç°ã€‚

### **3. æ ‡å‡†åŒ–æ¥å£**
æ‰€æœ‰workflowéƒ½åº”è¯¥å®ç°ç»Ÿä¸€çš„æ¥å£è§„èŒƒã€‚

## ğŸ“ Workflowç›®å½•ç»“æ„æ ‡å‡†

```
mcp/workflow/{workflow_name}/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ workflow_config.toml     # ä¸»é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ routing_rules.yaml       # è·¯ç”±è§„åˆ™
â”‚   â”œâ”€â”€ processing_steps.json    # å¤„ç†æ­¥éª¤å®šä¹‰
â”‚   â””â”€â”€ quality_settings.toml    # è´¨é‡å’Œæ€§èƒ½è®¾ç½®
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ {workflow_name}.py       # ä¸»å·¥ä½œæµç±»
â”‚   â”œâ”€â”€ workflow_executor.py     # æ‰§è¡Œå™¨
â”‚   â”œâ”€â”€ step_processors/         # æ­¥éª¤å¤„ç†å™¨
â”‚   â””â”€â”€ utils/                   # å·¥å…·å‡½æ•°
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_{workflow_name}.py  # å•å…ƒæµ‹è¯•
â”‚   â”œâ”€â”€ integration_tests.py     # é›†æˆæµ‹è¯•
â”‚   â””â”€â”€ performance_tests.py     # æ€§èƒ½æµ‹è¯•
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ README.md               # ä½¿ç”¨è¯´æ˜
â”‚   â”œâ”€â”€ api_reference.md        # APIå‚è€ƒ
â”‚   â””â”€â”€ examples/               # ä½¿ç”¨ç¤ºä¾‹
â””â”€â”€ cli.py                      # å‘½ä»¤è¡Œæ¥å£
```

## âš™ï¸ é…ç½®æ–‡ä»¶è§„èŒƒ

### **workflow_config.toml**
```toml
[workflow]
name = "OCRå¤„ç†å·¥ä½œæµ"
version = "1.0.0"
description = "æ™ºèƒ½OCRå¤„ç†å’Œæ–‡æ¡£åˆ†æå·¥ä½œæµ"
author = "PowerAutomation Team"

[dependencies]
adapters = ["local_model_mcp", "cloud_search_mcp"]
required_models = ["qwen", "mistral", "gemini"]

[execution]
timeout = 300  # ç§’
max_retries = 3
parallel_processing = true
batch_size = 10

[monitoring]
enable_logging = true
log_level = "INFO"
metrics_collection = true
performance_tracking = true
```

### **routing_rules.yaml**
```yaml
routing_rules:
  # åŸºäºä»»åŠ¡ç±»å‹çš„è·¯ç”±
  task_type:
    ocr_simple: "local_model_mcp"
    ocr_complex: "cloud_search_mcp"
    handwriting: "cloud_search_mcp"
    table_extraction: "cloud_search_mcp"
  
  # åŸºäºè´¨é‡è¦æ±‚çš„è·¯ç”±
  quality_level:
    high: "cloud_search_mcp"
    medium: "local_model_mcp"
    fast: "local_model_mcp"
  
  # åŸºäºéšç§è¦æ±‚çš„è·¯ç”±
  privacy_level:
    sensitive: "local_model_mcp"
    normal: "cloud_search_mcp"
    public: "cloud_search_mcp"
  
  # åŸºäºæ–‡ä»¶å¤§å°çš„è·¯ç”±
  file_size:
    small: "local_model_mcp"    # < 5MB
    medium: "cloud_search_mcp"  # 5-20MB
    large: "cloud_search_mcp"   # > 20MB
```

### **processing_steps.json**
```json
{
  "steps": [
    {
      "id": "input_validation",
      "name": "è¾“å…¥éªŒè¯",
      "processor": "InputValidator",
      "required": true,
      "timeout": 10,
      "retry_count": 1
    },
    {
      "id": "preprocessing",
      "name": "å›¾åƒé¢„å¤„ç†",
      "processor": "ImagePreprocessor",
      "required": false,
      "timeout": 30,
      "retry_count": 2,
      "conditions": {
        "image_quality": "< 0.8"
      }
    },
    {
      "id": "adapter_selection",
      "name": "é€‚é…å™¨é€‰æ‹©",
      "processor": "AdapterSelector",
      "required": true,
      "timeout": 5,
      "retry_count": 1
    },
    {
      "id": "ocr_processing",
      "name": "OCRå¤„ç†",
      "processor": "OCRProcessor",
      "required": true,
      "timeout": 120,
      "retry_count": 3
    },
    {
      "id": "postprocessing",
      "name": "ç»“æœåå¤„ç†",
      "processor": "ResultPostprocessor",
      "required": true,
      "timeout": 30,
      "retry_count": 2
    },
    {
      "id": "quality_check",
      "name": "è´¨é‡æ£€æŸ¥",
      "processor": "QualityChecker",
      "required": false,
      "timeout": 15,
      "retry_count": 1,
      "conditions": {
        "quality_check_enabled": true
      }
    }
  ],
  "error_handling": {
    "on_step_failure": "retry_or_skip",
    "on_critical_failure": "abort_workflow",
    "fallback_adapter": "local_model_mcp"
  }
}
```

### **quality_settings.toml**
```toml
[quality]
# è´¨é‡é˜ˆå€¼è®¾ç½®
min_confidence = 0.8
min_accuracy = 0.9
max_processing_time = 300

[performance]
# æ€§èƒ½è®¾ç½®
enable_caching = true
cache_ttl = 3600
enable_compression = true
max_memory_usage = "2GB"

[cost_optimization]
# æˆæœ¬ä¼˜åŒ–è®¾ç½®
prefer_local = true
cost_threshold = 0.01  # ç¾å…ƒ
quality_cost_balance = 0.7  # 0-1ä¹‹é—´ï¼Œè¶Šé«˜è¶Šåå‘è´¨é‡

[fallback]
# é™çº§ç­–ç•¥
enable_fallback = true
fallback_quality_threshold = 0.6
max_fallback_attempts = 2
```

## ğŸ”§ WorkflowåŸºç¡€ç±»å®ç°

### **BaseWorkflowç±»**
```python
from abc import ABC, abstractmethod
from typing import Dict, Any, List
import toml
import yaml
import json
import logging

class BaseWorkflow(ABC):
    """å·¥ä½œæµåŸºç¡€ç±»"""
    
    def __init__(self, config_dir: str):
        self.config_dir = config_dir
        self.config = self._load_config()
        self.routing_rules = self._load_routing_rules()
        self.processing_steps = self._load_processing_steps()
        self.quality_settings = self._load_quality_settings()
        
        # åˆå§‹åŒ–adapter
        self.adapters = self._initialize_adapters()
        
        # è®¾ç½®æ—¥å¿—
        self.logger = self._setup_logging()
    
    def _load_config(self) -> Dict[str, Any]:
        """åŠ è½½ä¸»é…ç½®æ–‡ä»¶"""
        config_path = f"{self.config_dir}/workflow_config.toml"
        with open(config_path, 'r', encoding='utf-8') as f:
            return toml.load(f)
    
    def _load_routing_rules(self) -> Dict[str, Any]:
        """åŠ è½½è·¯ç”±è§„åˆ™"""
        rules_path = f"{self.config_dir}/routing_rules.yaml"
        with open(rules_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    
    def _load_processing_steps(self) -> Dict[str, Any]:
        """åŠ è½½å¤„ç†æ­¥éª¤"""
        steps_path = f"{self.config_dir}/processing_steps.json"
        with open(steps_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def _load_quality_settings(self) -> Dict[str, Any]:
        """åŠ è½½è´¨é‡è®¾ç½®"""
        quality_path = f"{self.config_dir}/quality_settings.toml"
        with open(quality_path, 'r', encoding='utf-8') as f:
            return toml.load(f)
    
    @abstractmethod
    def _initialize_adapters(self) -> Dict[str, Any]:
        """åˆå§‹åŒ–æ‰€éœ€çš„adapter"""
        pass
    
    def _setup_logging(self) -> logging.Logger:
        """è®¾ç½®æ—¥å¿—"""
        logger = logging.getLogger(self.config['workflow']['name'])
        logger.setLevel(self.config['monitoring']['log_level'])
        return logger
    
    def select_adapter(self, request: Dict[str, Any]) -> str:
        """æ ¹æ®è·¯ç”±è§„åˆ™é€‰æ‹©adapter"""
        # å®ç°è·¯ç”±é€»è¾‘
        pass
    
    def execute_step(self, step_config: Dict[str, Any], context: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œå•ä¸ªå¤„ç†æ­¥éª¤"""
        # å®ç°æ­¥éª¤æ‰§è¡Œé€»è¾‘
        pass
    
    def execute(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œå®Œæ•´å·¥ä½œæµ"""
        context = {"request": request, "results": {}}
        
        try:
            for step in self.processing_steps['steps']:
                if self._should_execute_step(step, context):
                    result = self.execute_step(step, context)
                    context['results'][step['id']] = result
            
            return self._format_final_result(context)
            
        except Exception as e:
            self.logger.error(f"å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}")
            return self._handle_workflow_error(e, context)
    
    @abstractmethod
    def _should_execute_step(self, step: Dict[str, Any], context: Dict[str, Any]) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥æ‰§è¡ŒæŸä¸ªæ­¥éª¤"""
        pass
    
    @abstractmethod
    def _format_final_result(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """æ ¼å¼åŒ–æœ€ç»ˆç»“æœ"""
        pass
    
    @abstractmethod
    def _handle_workflow_error(self, error: Exception, context: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†å·¥ä½œæµé”™è¯¯"""
        pass
```

## ğŸ§ª æµ‹è¯•æ¡†æ¶

### **æµ‹è¯•é…ç½®**
```python
# tests/test_config.py
import pytest
from pathlib import Path

@pytest.fixture
def test_config_dir():
    """æµ‹è¯•é…ç½®ç›®å½•"""
    return Path(__file__).parent / "test_configs"

@pytest.fixture
def sample_request():
    """ç¤ºä¾‹è¯·æ±‚"""
    return {
        "task_type": "ocr_simple",
        "image_path": "/path/to/test_image.jpg",
        "quality_level": "high",
        "privacy_level": "normal"
    }
```

### **å•å…ƒæµ‹è¯•ç¤ºä¾‹**
```python
# tests/test_workflow.py
import pytest
from src.ocr_workflow import OCRWorkflow

class TestOCRWorkflow:
    
    def test_adapter_selection(self, test_config_dir, sample_request):
        """æµ‹è¯•adapteré€‰æ‹©é€»è¾‘"""
        workflow = OCRWorkflow(test_config_dir)
        adapter = workflow.select_adapter(sample_request)
        assert adapter in ["local_model_mcp", "cloud_search_mcp"]
    
    def test_workflow_execution(self, test_config_dir, sample_request):
        """æµ‹è¯•å·¥ä½œæµæ‰§è¡Œ"""
        workflow = OCRWorkflow(test_config_dir)
        result = workflow.execute(sample_request)
        assert result['success'] is True
        assert 'ocr_result' in result
    
    def test_error_handling(self, test_config_dir):
        """æµ‹è¯•é”™è¯¯å¤„ç†"""
        workflow = OCRWorkflow(test_config_dir)
        invalid_request = {"invalid": "request"}
        result = workflow.execute(invalid_request)
        assert result['success'] is False
        assert 'error' in result
```

### **æ€§èƒ½æµ‹è¯•ç¤ºä¾‹**
```python
# tests/performance_tests.py
import time
import pytest
from src.ocr_workflow import OCRWorkflow

class TestPerformance:
    
    def test_processing_time(self, test_config_dir, sample_request):
        """æµ‹è¯•å¤„ç†æ—¶é—´"""
        workflow = OCRWorkflow(test_config_dir)
        
        start_time = time.time()
        result = workflow.execute(sample_request)
        end_time = time.time()
        
        processing_time = end_time - start_time
        max_time = workflow.quality_settings['quality']['max_processing_time']
        
        assert processing_time < max_time
        assert result['success'] is True
    
    def test_batch_processing(self, test_config_dir):
        """æµ‹è¯•æ‰¹é‡å¤„ç†æ€§èƒ½"""
        workflow = OCRWorkflow(test_config_dir)
        requests = [sample_request for _ in range(10)]
        
        start_time = time.time()
        results = workflow.batch_execute(requests)
        end_time = time.time()
        
        avg_time = (end_time - start_time) / len(requests)
        assert avg_time < 30  # å¹³å‡æ¯ä¸ªè¯·æ±‚ä¸è¶…è¿‡30ç§’
```

## ğŸ“‹ å¼€å‘æ£€æŸ¥æ¸…å•

### **æ–°Workflowå¼€å‘æ¸…å•**
- [ ] åˆ›å»ºæ ‡å‡†ç›®å½•ç»“æ„
- [ ] ç¼–å†™é…ç½®æ–‡ä»¶ (config/, routing_rules, processing_steps, quality_settings)
- [ ] å®ç°BaseWorkflowå­ç±»
- [ ] ç¼–å†™å•å…ƒæµ‹è¯•
- [ ] ç¼–å†™é›†æˆæµ‹è¯•
- [ ] ç¼–å†™æ€§èƒ½æµ‹è¯•
- [ ] åˆ›å»ºCLIæ¥å£
- [ ] ç¼–å†™æ–‡æ¡£å’Œç¤ºä¾‹
- [ ] æ€§èƒ½åŸºå‡†æµ‹è¯•
- [ ] ä»£ç å®¡æŸ¥å’Œä¼˜åŒ–

### **é…ç½®éªŒè¯æ¸…å•**
- [ ] é…ç½®æ–‡ä»¶è¯­æ³•æ­£ç¡®
- [ ] è·¯ç”±è§„åˆ™è¦†ç›–æ‰€æœ‰åœºæ™¯
- [ ] å¤„ç†æ­¥éª¤é€»è¾‘åˆç†
- [ ] è´¨é‡è®¾ç½®ç¬¦åˆè¦æ±‚
- [ ] é”™è¯¯å¤„ç†ç­–ç•¥å®Œå–„
- [ ] æ€§èƒ½å‚æ•°åˆç†
- [ ] ç›‘æ§é…ç½®å®Œæ•´

è¿™ä¸ªæŒ‡å—æä¾›äº†å®Œæ•´çš„workflowè®¾è®¡å’Œé…ç½®æ¡†æ¶ï¼Œç¡®ä¿æ‰€æœ‰workflowéƒ½èƒ½æ ‡å‡†åŒ–å¼€å‘å’Œéƒ¨ç½²ã€‚

