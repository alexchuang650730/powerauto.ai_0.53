"""
å›¾åƒé¢„å¤„ç†ä¼˜åŒ–å™¨ - é’ˆå¯¹ä¿é™©è¡¨å•çš„ä¸“ç”¨é¢„å¤„ç†ç®—æ³•
"""

import cv2
import numpy as np
from PIL import Image, ImageEnhance, ImageFilter
import logging
from typing import Tuple, List, Optional
from dataclasses import dataclass
import os

logger = logging.getLogger(__name__)

@dataclass
class PreprocessConfig:
    """é¢„å¤„ç†é…ç½®"""
    # å›¾åƒå°ºå¯¸ä¼˜åŒ–
    max_width: int = 2000
    max_height: int = 2800
    min_width: int = 800
    min_height: int = 1000
    
    # å›¾åƒè´¨é‡
    dpi: int = 300
    quality: int = 95
    
    # é¢„å¤„ç†å‚æ•°
    contrast_factor: float = 1.2
    brightness_factor: float = 1.1
    sharpness_factor: float = 1.3
    
    # å™ªå£°å»é™¤
    denoise_strength: int = 3
    morphology_kernel_size: int = 2
    
    # è¡¨æ ¼æ£€æµ‹
    table_line_thickness: int = 2
    min_line_length: int = 50
    
    # æ‰‹å†™åŒºåŸŸæ£€æµ‹
    handwriting_threshold: float = 0.3
    text_region_padding: int = 5

class ImagePreprocessor:
    """å›¾åƒé¢„å¤„ç†å™¨"""
    
    def __init__(self, config: PreprocessConfig = None):
        self.config = config or PreprocessConfig()
        
    def optimize_for_ocr(self, image_path: str, output_path: str = None) -> str:
        """
        ä¸ºOCRä¼˜åŒ–å›¾åƒ
        
        Args:
            image_path: è¾“å…¥å›¾åƒè·¯å¾„
            output_path: è¾“å‡ºå›¾åƒè·¯å¾„ï¼ŒNoneåˆ™è‡ªåŠ¨ç”Ÿæˆ
            
        Returns:
            str: ä¼˜åŒ–åçš„å›¾åƒè·¯å¾„
        """
        logger.info(f"ğŸ”§ å¼€å§‹å›¾åƒé¢„å¤„ç†: {image_path}")
        
        # ç”Ÿæˆè¾“å‡ºè·¯å¾„
        if output_path is None:
            base_name = os.path.splitext(os.path.basename(image_path))[0]
            output_path = f"{base_name}_optimized.jpg"
        
        # è¯»å–å›¾åƒ
        image = cv2.imread(image_path)
        if image is None:
            raise ValueError(f"æ— æ³•è¯»å–å›¾åƒ: {image_path}")
        
        original_shape = image.shape
        logger.info(f"ğŸ“ åŸå§‹å›¾åƒå°ºå¯¸: {original_shape[1]}x{original_shape[0]}")
        
        # é¢„å¤„ç†æµæ°´çº¿
        processed_image = self._preprocessing_pipeline(image)
        
        # ä¿å­˜ä¼˜åŒ–åçš„å›¾åƒ
        cv2.imwrite(output_path, processed_image, [
            cv2.IMWRITE_JPEG_QUALITY, self.config.quality
        ])
        
        final_shape = processed_image.shape
        logger.info(f"âœ… é¢„å¤„ç†å®Œæˆ: {final_shape[1]}x{final_shape[0]} -> {output_path}")
        
        return output_path
    
    def _preprocessing_pipeline(self, image: np.ndarray) -> np.ndarray:
        """é¢„å¤„ç†æµæ°´çº¿"""
        
        # 1. å°ºå¯¸ä¼˜åŒ– - å‡å°‘å†…å­˜å ç”¨
        image = self._resize_image(image)
        
        # 2. é¢œè‰²ç©ºé—´è½¬æ¢
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray = image.copy()
        
        # 3. å™ªå£°å»é™¤
        denoised = self._remove_noise(gray)
        
        # 4. å¯¹æ¯”åº¦å’Œäº®åº¦å¢å¼º
        enhanced = self._enhance_contrast_brightness(denoised)
        
        # 5. é”åŒ–å¤„ç†
        sharpened = self._sharpen_image(enhanced)
        
        # 6. è¡¨æ ¼çº¿æ¡å¢å¼º
        table_enhanced = self._enhance_table_lines(sharpened)
        
        # 7. æ‰‹å†™åŒºåŸŸä¼˜åŒ–
        final_image = self._optimize_handwriting_regions(table_enhanced)
        
        return final_image
    
    def _resize_image(self, image: np.ndarray) -> np.ndarray:
        """æ™ºèƒ½è°ƒæ•´å›¾åƒå°ºå¯¸"""
        height, width = image.shape[:2]
        
        # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹
        scale_w = self.config.max_width / width
        scale_h = self.config.max_height / height
        scale = min(scale_w, scale_h, 1.0)  # ä¸æ”¾å¤§å›¾åƒ
        
        # ç¡®ä¿æœ€å°å°ºå¯¸
        if width * scale < self.config.min_width:
            scale = self.config.min_width / width
        if height * scale < self.config.min_height:
            scale = self.config.min_height / height
        
        if scale != 1.0:
            new_width = int(width * scale)
            new_height = int(height * scale)
            
            # ä½¿ç”¨é«˜è´¨é‡æ’å€¼
            image = cv2.resize(
                image, 
                (new_width, new_height), 
                interpolation=cv2.INTER_CUBIC
            )
            logger.info(f"ğŸ“ å›¾åƒç¼©æ”¾: {width}x{height} -> {new_width}x{new_height} (æ¯”ä¾‹: {scale:.2f})")
        
        return image
    
    def _remove_noise(self, image: np.ndarray) -> np.ndarray:
        """å»é™¤å™ªå£°"""
        # é«˜æ–¯æ¨¡ç³Šå»å™ª
        blurred = cv2.GaussianBlur(image, (3, 3), 0)
        
        # éå±€éƒ¨å‡å€¼å»å™ª
        denoised = cv2.fastNlMeansDenoising(
            blurred, 
            None, 
            self.config.denoise_strength, 
            7, 
            21
        )
        
        # å½¢æ€å­¦æ“ä½œå»é™¤å°å™ªç‚¹
        kernel = np.ones((self.config.morphology_kernel_size, self.config.morphology_kernel_size), np.uint8)
        cleaned = cv2.morphologyEx(denoised, cv2.MORPH_CLOSE, kernel)
        
        return cleaned
    
    def _enhance_contrast_brightness(self, image: np.ndarray) -> np.ndarray:
        """å¢å¼ºå¯¹æ¯”åº¦å’Œäº®åº¦"""
        # ç›´æ–¹å›¾å‡è¡¡åŒ–
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
        equalized = clahe.apply(image)
        
        # å¯¹æ¯”åº¦å’Œäº®åº¦è°ƒæ•´
        enhanced = cv2.convertScaleAbs(
            equalized,
            alpha=self.config.contrast_factor,
            beta=int(255 * (self.config.brightness_factor - 1))
        )
        
        return enhanced
    
    def _sharpen_image(self, image: np.ndarray) -> np.ndarray:
        """é”åŒ–å›¾åƒ"""
        # æ‹‰æ™®æ‹‰æ–¯é”åŒ–æ ¸
        kernel = np.array([
            [0, -1, 0],
            [-1, 5, -1],
            [0, -1, 0]
        ])
        
        sharpened = cv2.filter2D(image, -1, kernel)
        
        # æ··åˆåŸå›¾å’Œé”åŒ–å›¾
        alpha = self.config.sharpness_factor
        result = cv2.addWeighted(image, 1-alpha, sharpened, alpha, 0)
        
        return result
    
    def _enhance_table_lines(self, image: np.ndarray) -> np.ndarray:
        """å¢å¼ºè¡¨æ ¼çº¿æ¡"""
        # æ£€æµ‹æ°´å¹³çº¿
        horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (40, 1))
        horizontal_lines = cv2.morphologyEx(image, cv2.MORPH_OPEN, horizontal_kernel)
        
        # æ£€æµ‹å‚ç›´çº¿
        vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 40))
        vertical_lines = cv2.morphologyEx(image, cv2.MORPH_OPEN, vertical_kernel)
        
        # åˆå¹¶çº¿æ¡
        table_mask = cv2.addWeighted(horizontal_lines, 0.5, vertical_lines, 0.5, 0)
        
        # å¢å¼ºçº¿æ¡
        enhanced_lines = cv2.dilate(table_mask, np.ones((2, 2), np.uint8), iterations=1)
        
        # å°†å¢å¼ºçš„çº¿æ¡æ·»åŠ å›åŸå›¾
        result = cv2.addWeighted(image, 0.8, enhanced_lines, 0.2, 0)
        
        return result
    
    def _optimize_handwriting_regions(self, image: np.ndarray) -> np.ndarray:
        """ä¼˜åŒ–æ‰‹å†™åŒºåŸŸ"""
        # æ£€æµ‹æ–‡æœ¬åŒºåŸŸ
        text_regions = self._detect_text_regions(image)
        
        # å¯¹æ¯ä¸ªæ–‡æœ¬åŒºåŸŸè¿›è¡Œä¼˜åŒ–
        result = image.copy()
        
        for region in text_regions:
            x, y, w, h = region
            
            # æå–åŒºåŸŸ
            roi = image[y:y+h, x:x+w]
            
            # æ‰‹å†™ä¼˜åŒ–å¤„ç†
            optimized_roi = self._optimize_handwriting_roi(roi)
            
            # æ”¾å›åŸå›¾
            result[y:y+h, x:x+w] = optimized_roi
        
        return result
    
    def _detect_text_regions(self, image: np.ndarray) -> List[Tuple[int, int, int, int]]:
        """æ£€æµ‹æ–‡æœ¬åŒºåŸŸ"""
        # ä½¿ç”¨MSERæ£€æµ‹æ–‡æœ¬åŒºåŸŸ
        mser = cv2.MSER_create()
        regions, _ = mser.detectRegions(image)
        
        # è½¬æ¢ä¸ºè¾¹ç•Œæ¡†
        bboxes = []
        for region in regions:
            x, y, w, h = cv2.boundingRect(region.reshape(-1, 1, 2))
            
            # è¿‡æ»¤å¤ªå°çš„åŒºåŸŸ
            if w > 20 and h > 10:
                # æ·»åŠ padding
                padding = self.config.text_region_padding
                x = max(0, x - padding)
                y = max(0, y - padding)
                w = min(image.shape[1] - x, w + 2 * padding)
                h = min(image.shape[0] - y, h + 2 * padding)
                
                bboxes.append((x, y, w, h))
        
        return bboxes
    
    def _optimize_handwriting_roi(self, roi: np.ndarray) -> np.ndarray:
        """ä¼˜åŒ–æ‰‹å†™åŒºåŸŸ"""
        # äºŒå€¼åŒ–
        _, binary = cv2.threshold(roi, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        
        # å½¢æ€å­¦æ“ä½œè¿æ¥æ–­å¼€çš„ç¬”ç”»
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2, 2))
        connected = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)
        
        # å»é™¤å°å™ªç‚¹
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (1, 1))
        cleaned = cv2.morphologyEx(connected, cv2.MORPH_OPEN, kernel)
        
        return cleaned
    
    def create_multiple_versions(self, image_path: str) -> List[str]:
        """
        åˆ›å»ºå¤šä¸ªé¢„å¤„ç†ç‰ˆæœ¬ç”¨äºä¸åŒOCRå¼•æ“
        
        Returns:
            List[str]: ä¸åŒé¢„å¤„ç†ç‰ˆæœ¬çš„æ–‡ä»¶è·¯å¾„
        """
        base_name = os.path.splitext(os.path.basename(image_path))[0]
        versions = []
        
        # ç‰ˆæœ¬1: æ ‡å‡†é¢„å¤„ç†
        standard_config = PreprocessConfig()
        standard_processor = ImagePreprocessor(standard_config)
        standard_path = f"{base_name}_standard.jpg"
        standard_processor.optimize_for_ocr(image_path, standard_path)
        versions.append(standard_path)
        
        # ç‰ˆæœ¬2: é«˜å¯¹æ¯”åº¦ç‰ˆæœ¬ï¼ˆé€‚åˆTesseractï¼‰
        high_contrast_config = PreprocessConfig(
            contrast_factor=1.5,
            brightness_factor=1.0,
            sharpness_factor=1.5
        )
        high_contrast_processor = ImagePreprocessor(high_contrast_config)
        high_contrast_path = f"{base_name}_high_contrast.jpg"
        high_contrast_processor.optimize_for_ocr(image_path, high_contrast_path)
        versions.append(high_contrast_path)
        
        # ç‰ˆæœ¬3: å¹³æ»‘ç‰ˆæœ¬ï¼ˆé€‚åˆEasyOCRï¼‰
        smooth_config = PreprocessConfig(
            contrast_factor=1.1,
            brightness_factor=1.2,
            sharpness_factor=1.0,
            denoise_strength=5
        )
        smooth_processor = ImagePreprocessor(smooth_config)
        smooth_path = f"{base_name}_smooth.jpg"
        smooth_processor.optimize_for_ocr(image_path, smooth_path)
        versions.append(smooth_path)
        
        logger.info(f"âœ… åˆ›å»ºäº† {len(versions)} ä¸ªé¢„å¤„ç†ç‰ˆæœ¬")
        return versions

# æµ‹è¯•å‡½æ•°
def test_preprocessing():
    """æµ‹è¯•é¢„å¤„ç†åŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•å›¾åƒé¢„å¤„ç†å™¨")
    print("=" * 50)
    
    # æµ‹è¯•å›¾åƒè·¯å¾„
    test_image = "/home/ubuntu/upload/å¼µå®¶éŠ“_1.jpg"
    
    if not os.path.exists(test_image):
        print(f"âŒ æµ‹è¯•å›¾åƒä¸å­˜åœ¨: {test_image}")
        return
    
    # åˆ›å»ºé¢„å¤„ç†å™¨
    preprocessor = ImagePreprocessor()
    
    try:
        # å•ç‰ˆæœ¬ä¼˜åŒ–
        print("ğŸ“¸ å•ç‰ˆæœ¬é¢„å¤„ç†æµ‹è¯•...")
        optimized_path = preprocessor.optimize_for_ocr(test_image)
        print(f"âœ… ä¼˜åŒ–å®Œæˆ: {optimized_path}")
        
        # å¤šç‰ˆæœ¬ä¼˜åŒ–
        print("\nğŸ“¸ å¤šç‰ˆæœ¬é¢„å¤„ç†æµ‹è¯•...")
        versions = preprocessor.create_multiple_versions(test_image)
        print(f"âœ… åˆ›å»ºç‰ˆæœ¬: {versions}")
        
        # æ˜¾ç¤ºæ–‡ä»¶å¤§å°å¯¹æ¯”
        original_size = os.path.getsize(test_image) / 1024 / 1024
        print(f"\nğŸ“Š æ–‡ä»¶å¤§å°å¯¹æ¯”:")
        print(f"åŸå§‹å›¾åƒ: {original_size:.2f} MB")
        
        for version in versions:
            if os.path.exists(version):
                size = os.path.getsize(version) / 1024 / 1024
                reduction = (1 - size / original_size) * 100
                print(f"{version}: {size:.2f} MB (å‡å°‘ {reduction:.1f}%)")
        
    except Exception as e:
        print(f"âŒ é¢„å¤„ç†æµ‹è¯•å¤±è´¥: {e}")

if __name__ == "__main__":
    test_preprocessing()

