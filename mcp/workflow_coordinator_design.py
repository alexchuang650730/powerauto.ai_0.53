#!/usr/bin/env python3
"""
WorkflowCoordinator + MCPCoordinator å±‚çº§æ¶æ„è®¾è®¡

è§£å†³å¤§workflow MCP vs å°MCPçš„é€‰æ‹©é—®é¢˜ï¼Œå»ºç«‹æ¸…æ™°çš„å±‚çº§å†³ç­–æ¶æ„ã€‚

æ¶æ„å±‚çº§ï¼š
1. WorkflowCoordinator (æœ€é«˜å±‚) - å†³å®šæ˜¯å¦éœ€è¦å¤§workflow MCP
2. MCPCoordinator (ä¸­é—´å±‚) - é€‰æ‹©å…·ä½“çš„å°MCPï¼Œç®¡ç†äº¤äº’æ•°æ®  
3. Individual MCPs (æ‰§è¡Œå±‚) - æ‰§è¡Œå…·ä½“ä¸šåŠ¡é€»è¾‘

è®¾è®¡åŸåˆ™ï¼š
- å¤æ‚ä»»åŠ¡ â†’ WorkflowCoordinator â†’ Workflow MCP
- ç®€å•ä»»åŠ¡ â†’ WorkflowCoordinator â†’ MCPCoordinator â†’ Individual MCP
- æ‰€æœ‰äº¤äº’æ•°æ®ç»Ÿä¸€ç”±MCPCoordinatorç®¡ç†
"""

import asyncio
import json
import time
import re
from datetime import datetime
from typing import Dict, List, Any, Optional, Union, Tuple
from dataclasses import dataclass
from enum import Enum
import logging

# ============================================================================
# 1. æ ¸å¿ƒæšä¸¾å’Œæ•°æ®ç»“æ„
# ============================================================================

class TaskComplexity(Enum):
    """ä»»åŠ¡å¤æ‚åº¦"""
    SIMPLE = "simple"           # å•ä¸€MCPå¯å¤„ç†
    MODERATE = "moderate"       # éœ€è¦2-3ä¸ªMCPåä½œ
    COMPLEX = "complex"         # éœ€è¦workflow MCP
    ENTERPRISE = "enterprise"   # éœ€è¦ä¼ä¸šçº§workflow

class WorkflowType(Enum):
    """Workflowç±»å‹"""
    OCR_PIPELINE = "ocr_pipeline"                    # OCRå¤„ç†æµæ°´çº¿
    DATA_ANALYSIS_WORKFLOW = "data_analysis_workflow" # æ•°æ®åˆ†æå·¥ä½œæµ
    DOCUMENT_PROCESSING = "document_processing"       # æ–‡æ¡£å¤„ç†å·¥ä½œæµ
    MULTI_MODAL_ANALYSIS = "multi_modal_analysis"    # å¤šæ¨¡æ€åˆ†æå·¥ä½œæµ
    AUTOMATION_WORKFLOW = "automation_workflow"      # è‡ªåŠ¨åŒ–å·¥ä½œæµ

class MCPCategory(Enum):
    """MCPç±»åˆ«"""
    WORKFLOW_MCP = "workflow_mcp"     # å¤§workflow MCP
    FUNCTIONAL_MCP = "functional_mcp" # åŠŸèƒ½æ€§å°MCP

class IndividualMCPType(Enum):
    """ä¸ªä½“MCPç±»å‹"""
    LOCAL_MODEL = "local_model_mcp"
    CLOUD_SEARCH = "cloud_search_mcp"
    CLOUD_EDGE_DATA = "cloud_edge_data_mcp"

@dataclass
class TaskAnalysisResult:
    """ä»»åŠ¡åˆ†æç»“æœ"""
    complexity: TaskComplexity
    requires_workflow: bool
    recommended_workflow_type: Optional[WorkflowType]
    recommended_mcp_type: Optional[IndividualMCPType]
    confidence: float
    reasoning: str
    estimated_steps: int
    cross_domain: bool

@dataclass
class RoutingDecision:
    """è·¯ç”±å†³ç­–"""
    decision_type: str  # "workflow" or "individual_mcp"
    target: Union[WorkflowType, IndividualMCPType]
    confidence: float
    reasoning: str
    fallback_options: List[Union[WorkflowType, IndividualMCPType]]

# ============================================================================
# 2. ä»»åŠ¡å¤æ‚åº¦åˆ†æå™¨
# ============================================================================

class TaskComplexityAnalyzer:
    """
    ä»»åŠ¡å¤æ‚åº¦åˆ†æå™¨
    
    åˆ†æç”¨æˆ·è¯·æ±‚çš„å¤æ‚åº¦ï¼Œåˆ¤æ–­æ˜¯å¦éœ€è¦workflow MCP
    """
    
    def __init__(self):
        self.workflow_keywords = {
            WorkflowType.OCR_PIPELINE: [
                "æ‰¹é‡OCR", "æ–‡æ¡£å¤„ç†æµç¨‹", "å›¾åƒè¯†åˆ«æµæ°´çº¿", "å¤šæ–‡æ¡£åˆ†æ",
                "OCRåå¤„ç†", "æ–‡æ¡£ç»“æ„åŒ–", "è¡¨æ ¼æå–åˆ†æ"
            ],
            WorkflowType.DATA_ANALYSIS_WORKFLOW: [
                "æ•°æ®åˆ†ææµç¨‹", "ç»Ÿè®¡åˆ†æ", "æ•°æ®æŒ–æ˜", "æŠ¥å‘Šç”Ÿæˆ",
                "æ•°æ®å¯è§†åŒ–", "è¶‹åŠ¿åˆ†æ", "é¢„æµ‹å»ºæ¨¡"
            ],
            WorkflowType.DOCUMENT_PROCESSING: [
                "æ–‡æ¡£è½¬æ¢", "æ ¼å¼è½¬æ¢", "æ–‡æ¡£åˆå¹¶", "æ–‡æ¡£æ‹†åˆ†",
                "æ–‡æ¡£æ ‡å‡†åŒ–", "æ–‡æ¡£å½’æ¡£", "æ–‡æ¡£å®¡æ ¸"
            ],
            WorkflowType.MULTI_MODAL_ANALYSIS: [
                "å¤šæ¨¡æ€åˆ†æ", "å›¾æ–‡ç»“åˆ", "éŸ³è§†é¢‘åˆ†æ", "ç»¼åˆåˆ†æ",
                "è·¨åª’ä½“", "å¤šæºæ•°æ®", "èåˆåˆ†æ"
            ],
            WorkflowType.AUTOMATION_WORKFLOW: [
                "è‡ªåŠ¨åŒ–æµç¨‹", "æ‰¹é‡å¤„ç†", "å®šæ—¶ä»»åŠ¡", "å·¥ä½œæµ",
                "æµç¨‹è‡ªåŠ¨åŒ–", "æ‰¹é‡æ“ä½œ", "è‡ªåŠ¨åŒ–è„šæœ¬"
            ]
        }
        
        self.complexity_indicators = {
            TaskComplexity.SIMPLE: [
                "å•ä¸ª", "ä¸€å¼ ", "ç®€å•", "å¿«é€Ÿ", "ç›´æ¥"
            ],
            TaskComplexity.MODERATE: [
                "å‡ ä¸ª", "å¤šä¸ª", "å¯¹æ¯”", "åˆ†æ", "å¤„ç†"
            ],
            TaskComplexity.COMPLEX: [
                "æ‰¹é‡", "æµç¨‹", "å·¥ä½œæµ", "è‡ªåŠ¨åŒ–", "ç³»ç»Ÿ",
                "å®Œæ•´", "ç«¯åˆ°ç«¯", "å…¨æµç¨‹"
            ],
            TaskComplexity.ENTERPRISE: [
                "ä¼ä¸šçº§", "å¤§è§„æ¨¡", "ç”Ÿäº§ç¯å¢ƒ", "é›†æˆ", "éƒ¨ç½²",
                "ç›‘æ§", "ç®¡ç†", "è¿ç»´"
            ]
        }
        
        self.cross_domain_keywords = [
            "ç»“åˆ", "æ•´åˆ", "èåˆ", "ç»¼åˆ", "è·¨", "å¤šç§", "ä¸åŒ"
        ]
    
    def analyze_task(self, user_request: str, context: Dict[str, Any] = None) -> TaskAnalysisResult:
        """
        åˆ†æä»»åŠ¡å¤æ‚åº¦
        
        Args:
            user_request: ç”¨æˆ·è¯·æ±‚
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            
        Returns:
            ä»»åŠ¡åˆ†æç»“æœ
        """
        
        request_lower = user_request.lower()
        
        # 1. æ£€æµ‹æ˜¯å¦éœ€è¦workflow
        workflow_type, workflow_confidence = self._detect_workflow_type(request_lower)
        
        # 2. åˆ†æå¤æ‚åº¦
        complexity = self._analyze_complexity(request_lower)
        
        # 3. æ£€æµ‹è·¨åŸŸéœ€æ±‚
        cross_domain = self._detect_cross_domain(request_lower)
        
        # 4. ä¼°ç®—æ­¥éª¤æ•°
        estimated_steps = self._estimate_steps(request_lower, complexity)
        
        # 5. å†³å®šæ˜¯å¦éœ€è¦workflow
        requires_workflow = self._requires_workflow_decision(
            complexity, workflow_confidence, cross_domain, estimated_steps
        )
        
        # 6. æ¨èä¸ªä½“MCPï¼ˆå¦‚æœä¸éœ€è¦workflowï¼‰
        recommended_mcp = None if requires_workflow else self._recommend_individual_mcp(request_lower)
        
        # 7. ç”Ÿæˆæ¨ç†è¯´æ˜
        reasoning = self._generate_reasoning(
            complexity, workflow_type, cross_domain, estimated_steps, requires_workflow
        )
        
        # 8. è®¡ç®—æ€»ä½“ç½®ä¿¡åº¦
        overall_confidence = self._calculate_overall_confidence(
            workflow_confidence, complexity, cross_domain
        )
        
        return TaskAnalysisResult(
            complexity=complexity,
            requires_workflow=requires_workflow,
            recommended_workflow_type=workflow_type if requires_workflow else None,
            recommended_mcp_type=recommended_mcp,
            confidence=overall_confidence,
            reasoning=reasoning,
            estimated_steps=estimated_steps,
            cross_domain=cross_domain
        )
    
    def _detect_workflow_type(self, request_lower: str) -> Tuple[Optional[WorkflowType], float]:
        """æ£€æµ‹workflowç±»å‹"""
        
        best_match = None
        best_score = 0.0
        
        for workflow_type, keywords in self.workflow_keywords.items():
            score = 0.0
            for keyword in keywords:
                if keyword.lower() in request_lower:
                    score += 1.0
            
            # å½’ä¸€åŒ–åˆ†æ•°
            normalized_score = score / len(keywords)
            
            if normalized_score > best_score:
                best_score = normalized_score
                best_match = workflow_type
        
        return best_match, best_score
    
    def _analyze_complexity(self, request_lower: str) -> TaskComplexity:
        """åˆ†æå¤æ‚åº¦"""
        
        complexity_scores = {}
        
        for complexity, indicators in self.complexity_indicators.items():
            score = 0
            for indicator in indicators:
                if indicator in request_lower:
                    score += 1
            complexity_scores[complexity] = score
        
        # æ‰¾åˆ°å¾—åˆ†æœ€é«˜çš„å¤æ‚åº¦
        if complexity_scores[TaskComplexity.ENTERPRISE] > 0:
            return TaskComplexity.ENTERPRISE
        elif complexity_scores[TaskComplexity.COMPLEX] > 0:
            return TaskComplexity.COMPLEX
        elif complexity_scores[TaskComplexity.MODERATE] > 0:
            return TaskComplexity.MODERATE
        else:
            return TaskComplexity.SIMPLE
    
    def _detect_cross_domain(self, request_lower: str) -> bool:
        """æ£€æµ‹è·¨åŸŸéœ€æ±‚"""
        
        for keyword in self.cross_domain_keywords:
            if keyword in request_lower:
                return True
        
        # æ£€æµ‹å¤šä¸ªé¢†åŸŸå…³é”®è¯
        domain_keywords = ["ocr", "å›¾åƒ", "æ–‡æœ¬", "æ•°æ®", "åˆ†æ", "å¤„ç†"]
        domain_count = sum(1 for keyword in domain_keywords if keyword in request_lower)
        
        return domain_count >= 2
    
    def _estimate_steps(self, request_lower: str, complexity: TaskComplexity) -> int:
        """ä¼°ç®—å¤„ç†æ­¥éª¤æ•°"""
        
        base_steps = {
            TaskComplexity.SIMPLE: 1,
            TaskComplexity.MODERATE: 3,
            TaskComplexity.COMPLEX: 5,
            TaskComplexity.ENTERPRISE: 8
        }
        
        steps = base_steps[complexity]
        
        # æ ¹æ®å…³é”®è¯è°ƒæ•´
        step_keywords = ["ç„¶å", "æ¥ç€", "ä¹‹å", "å†", "æœ€å", "æ­¥éª¤"]
        for keyword in step_keywords:
            if keyword in request_lower:
                steps += 1
        
        return min(steps, 10)  # æœ€å¤š10æ­¥
    
    def _requires_workflow_decision(self, 
                                  complexity: TaskComplexity,
                                  workflow_confidence: float,
                                  cross_domain: bool,
                                  estimated_steps: int) -> bool:
        """å†³å®šæ˜¯å¦éœ€è¦workflow"""
        
        # ä¼ä¸šçº§ä»»åŠ¡å¿…é¡»ä½¿ç”¨workflow
        if complexity == TaskComplexity.ENTERPRISE:
            return True
        
        # å¤æ‚ä»»åŠ¡ä¸”æœ‰workflowåŒ¹é…
        if complexity == TaskComplexity.COMPLEX and workflow_confidence > 0.3:
            return True
        
        # è·¨åŸŸä¸”æ­¥éª¤å¤š
        if cross_domain and estimated_steps >= 3:
            return True
        
        # æ­¥éª¤å¾ˆå¤š
        if estimated_steps >= 5:
            return True
        
        return False
    
    def _recommend_individual_mcp(self, request_lower: str) -> IndividualMCPType:
        """æ¨èä¸ªä½“MCP"""
        
        # OCRç›¸å…³
        if any(keyword in request_lower for keyword in ["ocr", "å›¾åƒ", "è¯†åˆ«", "æ–‡å­—"]):
            return IndividualMCPType.CLOUD_SEARCH
        
        # æœ¬åœ°æ¨¡å‹ç›¸å…³
        if any(keyword in request_lower for keyword in ["æœ¬åœ°", "local", "ç¦»çº¿"]):
            return IndividualMCPType.LOCAL_MODEL
        
        # é»˜è®¤äº‘è¾¹ååŒ
        return IndividualMCPType.CLOUD_EDGE_DATA
    
    def _generate_reasoning(self, 
                          complexity: TaskComplexity,
                          workflow_type: Optional[WorkflowType],
                          cross_domain: bool,
                          estimated_steps: int,
                          requires_workflow: bool) -> str:
        """ç”Ÿæˆæ¨ç†è¯´æ˜"""
        
        reasons = []
        
        reasons.append(f"ä»»åŠ¡å¤æ‚åº¦: {complexity.value}")
        
        if workflow_type:
            reasons.append(f"æ£€æµ‹åˆ°workflowç±»å‹: {workflow_type.value}")
        
        if cross_domain:
            reasons.append("æ£€æµ‹åˆ°è·¨åŸŸéœ€æ±‚")
        
        reasons.append(f"é¢„ä¼°å¤„ç†æ­¥éª¤: {estimated_steps}")
        
        if requires_workflow:
            reasons.append("å»ºè®®ä½¿ç”¨workflow MCPå¤„ç†")
        else:
            reasons.append("å¯ä½¿ç”¨å•ä¸€MCPå¤„ç†")
        
        return "; ".join(reasons)
    
    def _calculate_overall_confidence(self, 
                                    workflow_confidence: float,
                                    complexity: TaskComplexity,
                                    cross_domain: bool) -> float:
        """è®¡ç®—æ€»ä½“ç½®ä¿¡åº¦"""
        
        base_confidence = 0.7
        
        # workflowåŒ¹é…åº¦åŠ æˆ
        base_confidence += workflow_confidence * 0.2
        
        # å¤æ‚åº¦åŠ æˆ
        complexity_bonus = {
            TaskComplexity.SIMPLE: 0.1,
            TaskComplexity.MODERATE: 0.05,
            TaskComplexity.COMPLEX: 0.0,
            TaskComplexity.ENTERPRISE: -0.05
        }
        base_confidence += complexity_bonus[complexity]
        
        # è·¨åŸŸæ£€æµ‹åŠ æˆ
        if cross_domain:
            base_confidence += 0.1
        
        return min(max(base_confidence, 0.0), 1.0)

# ============================================================================
# 3. WorkflowCoordinator (æœ€é«˜å±‚)
# ============================================================================

class WorkflowCoordinator:
    """
    å·¥ä½œæµåè°ƒå™¨ (æœ€é«˜å±‚)
    
    è´Ÿè´£å†³å®šæ˜¯å¦éœ€è¦å¤§workflow MCPï¼Œå¦‚æœä¸éœ€è¦åˆ™å§”æ‰˜ç»™MCPCoordinator
    """
    
    def __init__(self, mcp_coordinator):
        self.mcp_coordinator = mcp_coordinator
        self.task_analyzer = TaskComplexityAnalyzer()
        self.registered_workflows: Dict[WorkflowType, Any] = {}
        self.logger = logging.getLogger("WorkflowCoordinator")
        
        self.logger.info("WorkflowCoordinatoråˆå§‹åŒ–å®Œæˆ")
    
    def register_workflow_mcp(self, workflow_type: WorkflowType, workflow_instance: Any):
        """æ³¨å†Œworkflow MCP"""
        
        self.registered_workflows[workflow_type] = workflow_instance
        self.logger.info(f"æ³¨å†ŒWorkflow MCP: {workflow_type.value}")
    
    async def process_request(self, 
                            user_request: str,
                            context: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        å¤„ç†ç”¨æˆ·è¯·æ±‚ (æœ€é«˜å±‚å…¥å£)
        
        Args:
            user_request: ç”¨æˆ·è¯·æ±‚
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            
        Returns:
            å¤„ç†ç»“æœ
        """
        
        start_time = time.time()
        
        try:
            # 1. åˆ†æä»»åŠ¡å¤æ‚åº¦
            analysis_result = self.task_analyzer.analyze_task(user_request, context)
            
            self.logger.info(f"ä»»åŠ¡åˆ†æ: {analysis_result.reasoning}")
            
            # 2. è·¯ç”±å†³ç­–
            if analysis_result.requires_workflow:
                # ä½¿ç”¨workflow MCPå¤„ç†
                result = await self._process_with_workflow(
                    user_request, analysis_result, context
                )
                result["routing_level"] = "workflow"
                result["selected_workflow"] = analysis_result.recommended_workflow_type.value
            else:
                # å§”æ‰˜ç»™MCPCoordinatorå¤„ç†
                result = await self.mcp_coordinator.process_request(
                    user_request, "auto", context
                )
                result["routing_level"] = "individual_mcp"
                result["recommended_mcp"] = analysis_result.recommended_mcp_type.value if analysis_result.recommended_mcp_type else "auto"
            
            # 3. æ·»åŠ åˆ†æä¿¡æ¯
            result["task_analysis"] = {
                "complexity": analysis_result.complexity.value,
                "requires_workflow": analysis_result.requires_workflow,
                "confidence": analysis_result.confidence,
                "reasoning": analysis_result.reasoning,
                "estimated_steps": analysis_result.estimated_steps,
                "cross_domain": analysis_result.cross_domain
            }
            
            result["total_processing_time"] = time.time() - start_time
            
            return result
            
        except Exception as e:
            self.logger.error(f"WorkflowCoordinatorå¤„ç†å¤±è´¥: {e}")
            
            return {
                "success": False,
                "error": str(e),
                "routing_level": "error",
                "total_processing_time": time.time() - start_time
            }
    
    async def _process_with_workflow(self, 
                                   user_request: str,
                                   analysis_result: TaskAnalysisResult,
                                   context: Dict[str, Any]) -> Dict[str, Any]:
        """ä½¿ç”¨workflow MCPå¤„ç†"""
        
        workflow_type = analysis_result.recommended_workflow_type
        
        if workflow_type not in self.registered_workflows:
            # å¦‚æœæ²¡æœ‰æ³¨å†Œå¯¹åº”çš„workflowï¼Œé™çº§åˆ°MCPCoordinator
            self.logger.warning(f"Workflow MCPæœªæ³¨å†Œ: {workflow_type.value}ï¼Œé™çº§åˆ°MCPCoordinator")
            
            result = await self.mcp_coordinator.process_request(
                user_request, "auto", context
            )
            result["fallback_reason"] = f"Workflow MCPæœªæ³¨å†Œ: {workflow_type.value}"
            return result
        
        # æ‰§è¡Œworkflow MCP
        workflow_instance = self.registered_workflows[workflow_type]
        
        workflow_request = {
            "operation": "execute_workflow",
            "params": {
                "user_request": user_request,
                "analysis_result": analysis_result,
                "context": context
            }
        }
        
        if hasattr(workflow_instance, 'execute_workflow') and callable(workflow_instance.execute_workflow):
            result = workflow_instance.execute_workflow(workflow_request)
        else:
            result = {"success": False, "error": "Workflow MCPä¸æ”¯æŒexecute_workflowæ–¹æ³•"}
        
        return result
    
    def get_system_overview(self) -> Dict[str, Any]:
        """è·å–ç³»ç»Ÿæ€»è§ˆ"""
        
        mcp_status = self.mcp_coordinator.get_system_status()
        
        return {
            "workflow_coordinator": {
                "status": "active",
                "registered_workflows": [wf.value for wf in self.registered_workflows.keys()]
            },
            "mcp_coordinator": mcp_status,
            "architecture": {
                "levels": ["WorkflowCoordinator", "MCPCoordinator", "Individual MCPs"],
                "decision_flow": "WorkflowCoordinator â†’ åˆ†æä»»åŠ¡ â†’ é€‰æ‹©å±‚çº§ â†’ æ‰§è¡Œå¤„ç†"
            }
        }

# ============================================================================
# 4. ä½¿ç”¨ç¤ºä¾‹å’Œæ¼”ç¤º
# ============================================================================

async def demo_hierarchical_architecture():
    """å±‚çº§æ¶æ„æ¼”ç¤º"""
    
    print("ğŸ—ï¸ WorkflowCoordinator + MCPCoordinator å±‚çº§æ¶æ„æ¼”ç¤º")
    print("=" * 70)
    
    # å¯¼å…¥ä¹‹å‰çš„MCPCoordinator
    from mcp_coordinator_redesign import MCPCoordinator, MCPType
    
    # åˆå§‹åŒ–MCPCoordinator
    mcp_coordinator = MCPCoordinator()
    
    # æ¨¡æ‹Ÿæ³¨å†Œä¸ªä½“MCP
    class MockIndividualMCP:
        def __init__(self, name):
            self.name = name
        
        def process(self, request):
            return {
                "success": True,
                "response": f"{self.name} å¤„ç†å®Œæˆ",
                "cost": 0.001,
                "quality_score": 0.9
            }
    
    mcp_coordinator.register_mcp(MCPType.LOCAL_MODEL, MockIndividualMCP("LocalModelMCP"))
    mcp_coordinator.register_mcp(MCPType.CLOUD_SEARCH, MockIndividualMCP("CloudSearchMCP"))
    mcp_coordinator.register_mcp(MCPType.CLOUD_EDGE_DATA, MockIndividualMCP("CloudEdgeDataMCP"))
    
    # åˆå§‹åŒ–WorkflowCoordinator
    workflow_coordinator = WorkflowCoordinator(mcp_coordinator)
    
    # æ¨¡æ‹Ÿæ³¨å†Œworkflow MCP
    class MockWorkflowMCP:
        def __init__(self, name):
            self.name = name
        
        def execute_workflow(self, request):
            return {
                "success": True,
                "response": f"{self.name} workflowæ‰§è¡Œå®Œæˆ",
                "steps_executed": 5,
                "cost": 0.01,
                "quality_score": 0.95
            }
    
    workflow_coordinator.register_workflow_mcp(
        WorkflowType.OCR_PIPELINE, 
        MockWorkflowMCP("OCR Pipeline Workflow")
    )
    workflow_coordinator.register_workflow_mcp(
        WorkflowType.DATA_ANALYSIS_WORKFLOW,
        MockWorkflowMCP("Data Analysis Workflow")
    )
    
    # æµ‹è¯•ä¸åŒå¤æ‚åº¦çš„è¯·æ±‚
    test_requests = [
        {
            "request": "è¯†åˆ«è¿™å¼ å›¾ç‰‡ä¸­çš„æ–‡å­—",
            "expected": "ç®€å•ä»»åŠ¡ â†’ Individual MCP"
        },
        {
            "request": "æ‰¹é‡OCRå¤„ç†100ä¸ªæ–‡æ¡£ï¼Œç„¶åè¿›è¡Œæ•°æ®åˆ†æå’ŒæŠ¥å‘Šç”Ÿæˆ",
            "expected": "å¤æ‚ä»»åŠ¡ â†’ Workflow MCP"
        },
        {
            "request": "ä½¿ç”¨æœ¬åœ°æ¨¡å‹è¿›è¡Œæ¨ç†",
            "expected": "ç®€å•ä»»åŠ¡ â†’ Individual MCP"
        },
        {
            "request": "å»ºç«‹å®Œæ•´çš„æ–‡æ¡£å¤„ç†æµç¨‹ï¼ŒåŒ…æ‹¬OCRã€ç»“æ„åŒ–ã€åˆ†æå’Œå½’æ¡£",
            "expected": "å¤æ‚ä»»åŠ¡ â†’ Workflow MCP"
        },
        {
            "request": "å¯¹æ¯”åˆ†æä¸‰ä¸ªæ•°æ®æºçš„è¶‹åŠ¿",
            "expected": "ä¸­ç­‰ä»»åŠ¡ â†’ Individual MCP"
        }
    ]
    
    for i, test_case in enumerate(test_requests, 1):
        print(f"\nğŸ“ æµ‹è¯• {i}: {test_case['request']}")
        print(f"ğŸ¯ é¢„æœŸ: {test_case['expected']}")
        print("-" * 50)
        
        result = await workflow_coordinator.process_request(
            user_request=test_case["request"],
            context={"user_id": "demo_user", "priority": "normal"}
        )
        
        if result["success"]:
            print(f"âœ… å¤„ç†æˆåŠŸ")
            print(f"   è·¯ç”±å±‚çº§: {result['routing_level']}")
            
            if result["routing_level"] == "workflow":
                print(f"   é€‰æ‹©Workflow: {result['selected_workflow']}")
            else:
                print(f"   æ¨èMCP: {result.get('recommended_mcp', 'auto')}")
                if 'routing_info' in result:
                    print(f"   å®é™…é€‰æ‹©: {result['routing_info']['selected_mcp'].value}")
            
            print(f"   ä»»åŠ¡å¤æ‚åº¦: {result['task_analysis']['complexity']}")
            print(f"   éœ€è¦Workflow: {result['task_analysis']['requires_workflow']}")
            print(f"   åˆ†æç½®ä¿¡åº¦: {result['task_analysis']['confidence']:.2%}")
            print(f"   é¢„ä¼°æ­¥éª¤: {result['task_analysis']['estimated_steps']}")
            print(f"   è·¨åŸŸéœ€æ±‚: {result['task_analysis']['cross_domain']}")
            print(f"   å¤„ç†æ—¶é—´: {result['total_processing_time']:.3f}ç§’")
            print(f"   åˆ†æç†ç”±: {result['task_analysis']['reasoning']}")
            
        else:
            print(f"âŒ å¤„ç†å¤±è´¥: {result['error']}")
    
    # æ˜¾ç¤ºç³»ç»Ÿæ€»è§ˆ
    print(f"\nğŸ“Š ç³»ç»Ÿæ€»è§ˆ:")
    overview = workflow_coordinator.get_system_overview()
    
    print(f"   WorkflowCoordinator:")
    print(f"     çŠ¶æ€: {overview['workflow_coordinator']['status']}")
    print(f"     æ³¨å†ŒWorkflows: {overview['workflow_coordinator']['registered_workflows']}")
    
    print(f"   MCPCoordinator:")
    print(f"     æ³¨å†ŒMCPs: {overview['mcp_coordinator']['registered_mcps']}")
    
    print(f"   æ¶æ„å±‚çº§: {' â†’ '.join(overview['architecture']['levels'])}")
    print(f"   å†³ç­–æµç¨‹: {overview['architecture']['decision_flow']}")

if __name__ == "__main__":
    # è®¾ç½®æ—¥å¿—
    logging.basicConfig(level=logging.INFO, format='%(name)s - %(levelname)s - %(message)s')
    
    asyncio.run(demo_hierarchical_architecture())

